{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of the pretrained Japanese BERT model\n",
    "\n",
    "Finetune the pretrained model to solve multi-class classification problems.  \n",
    "This notebook requires the following objects:\n",
    "- trained sentencepiece model (model and vocab files)\n",
    "- pretraiend Japanese BERT model\n",
    "\n",
    "Dataset is livedoor ニュースコーパス in https://www.rondhuit.com/download.html.  \n",
    "We make test:dev:train = 2:2:6 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "- Full training data\n",
    "  - BERT with SentencePiece\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.98      0.94      0.96       178\n",
    "      it-life-hack       0.96      0.97      0.96       172\n",
    "     kaden-channel       0.99      0.98      0.99       176\n",
    "    livedoor-homme       0.98      0.88      0.93        95\n",
    "       movie-enter       0.96      0.99      0.98       158\n",
    "            peachy       0.94      0.98      0.96       174\n",
    "              smax       0.98      0.99      0.99       167\n",
    "      sports-watch       0.98      1.00      0.99       190\n",
    "        topic-news       0.99      0.98      0.98       163\n",
    "\n",
    "         micro avg       0.97      0.97      0.97      1473\n",
    "         macro avg       0.97      0.97      0.97      1473\n",
    "      weighted avg       0.97      0.97      0.97      1473\n",
    "    ```\n",
    "  - sklearn GradientBoostingClassifier with MeCab\n",
    "    ```\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.89      0.86      0.88       178\n",
    "      it-life-hack       0.91      0.90      0.91       172\n",
    "     kaden-channel       0.90      0.94      0.92       176\n",
    "    livedoor-homme       0.79      0.74      0.76        95\n",
    "       movie-enter       0.93      0.96      0.95       158\n",
    "            peachy       0.87      0.92      0.89       174\n",
    "              smax       0.99      1.00      1.00       167\n",
    "      sports-watch       0.93      0.98      0.96       190\n",
    "        topic-news       0.96      0.86      0.91       163\n",
    "\n",
    "         micro avg       0.92      0.92      0.92      1473\n",
    "         macro avg       0.91      0.91      0.91      1473\n",
    "      weighted avg       0.92      0.92      0.91      1473\n",
    "    ```\n",
    "\n",
    "- Small training data (1/5 of full training data)\n",
    "  - BERT with SentencePiece\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.97      0.87      0.92       178\n",
    "      it-life-hack       0.86      0.86      0.86       172\n",
    "     kaden-channel       0.95      0.94      0.95       176\n",
    "    livedoor-homme       0.82      0.82      0.82        95\n",
    "       movie-enter       0.97      0.99      0.98       158\n",
    "            peachy       0.89      0.95      0.92       174\n",
    "              smax       0.94      0.96      0.95       167\n",
    "      sports-watch       0.97      0.97      0.97       190\n",
    "        topic-news       0.94      0.94      0.94       163\n",
    "\n",
    "         micro avg       0.93      0.93      0.93      1473\n",
    "         macro avg       0.92      0.92      0.92      1473\n",
    "      weighted avg       0.93      0.93      0.93      1473\n",
    "    ```\n",
    "  - sklearn GradientBoostingClassifier with MeCab\n",
    "    ```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "    dokujo-tsushin       0.82      0.71      0.76       178\n",
    "      it-life-hack       0.86      0.88      0.87       172\n",
    "     kaden-channel       0.91      0.87      0.89       176\n",
    "    livedoor-homme       0.67      0.63      0.65        95\n",
    "       movie-enter       0.87      0.95      0.91       158\n",
    "            peachy       0.70      0.78      0.73       174\n",
    "              smax       1.00      1.00      1.00       167\n",
    "      sports-watch       0.87      0.95      0.91       190\n",
    "        topic-news       0.92      0.82      0.87       163\n",
    "\n",
    "         micro avg       0.85      0.85      0.85      1473\n",
    "         macro avg       0.85      0.84      0.84      1473\n",
    "      weighted avg       0.86      0.85      0.85      1473\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hiroki-iida/work/bert-japanese/notebook/../config.ini']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import tarfile \n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "CURDIR = os.getcwd()\n",
    "CONFIGPATH = os.path.join(CURDIR, os.pardir, 'config.ini')\n",
    "config = configparser.ConfigParser()\n",
    "config.read(CONFIGPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparing\n",
    "\n",
    "You need execute the following cells just once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEURL = config['FINETUNING-DATA']['FILEURL']\n",
    "FILEPATH = config['FINETUNING-DATA']['FILEPATH']\n",
    "EXTRACTDIR = config['FINETUNING-DATA']['TEXTDIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unzip data(livedoor corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 392 ms, total: 1.5 s\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "urlretrieve(FILEURL, FILEPATH)\n",
    "\n",
    "mode = \"r:gz\"\n",
    "tar = tarfile.open(FILEPATH, mode) \n",
    "tar.extractall(EXTRACTDIR) \n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt(filename):\n",
    "    with open(filename) as text_file:\n",
    "        # 0: URL, 1: timestamp\n",
    "        text = text_file.readlines()[2:]\n",
    "        text = [sentence.strip() for sentence in text]\n",
    "        text = list(filter(lambda line: line != '', text))\n",
    "        return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [ \n",
    "    name for name \n",
    "    in os.listdir( os.path.join(EXTRACTDIR, \"text\") ) \n",
    "    if os.path.isdir( os.path.join(EXTRACTDIR, \"text\", name) ) ]\n",
    "\n",
    "categories = sorted(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dokujo-tsushin',\n",
       " 'it-life-hack',\n",
       " 'kaden-channel',\n",
       " 'livedoor-homme',\n",
       " 'movie-enter',\n",
       " 'peachy',\n",
       " 'smax',\n",
       " 'sports-watch',\n",
       " 'topic-news']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans({\n",
    "    '\\n': '',\n",
    "    '\\t': '　',\n",
    "    '\\r': '',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 120 ms, total: 1.28 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_text = []\n",
    "all_label = []\n",
    "\n",
    "for cat in categories:\n",
    "    files = glob.glob(os.path.join(EXTRACTDIR, \"text\", cat, \"{}*.txt\".format(cat)))\n",
    "    files = sorted(files)\n",
    "    body = [ extract_txt(elem).translate(table) for elem in files ]\n",
    "    label = [cat] * len(body)\n",
    "    \n",
    "    all_text.extend(body)\n",
    "    all_label.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text' : all_text, 'label' : all_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だ...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0  友人代表のスピーチ、独女はどうこなしている？もうすぐジューン・ブライドと呼ばれる６月。独女の...  dokujo-tsushin\n",
       "1  ネットで断ち切れない元カレとの縁携帯電話が普及する以前、恋人への連絡ツールは一般電話が普通だ...  dokujo-tsushin\n",
       "2  相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？「男性はやっぱり、女性の“すっぴん”が...  dokujo-tsushin\n",
       "3  ムダな抵抗！？ 加齢の現実ヒップの加齢による変化は「たわむ→下がる→内に流れる」、バストは「...  dokujo-tsushin\n",
       "4  税金を払うのは私たちなんですけど！6月から支給される子ども手当だが、当初は子ども一人当たり月...  dokujo-tsushin"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=23).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>新記録でロンドンに乗り込む“バタフライの女王”加藤ゆか3日に行われた競泳の日本選手権で、女子...</td>\n",
       "      <td>sports-watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>家電チャンネルの記事も配信！向かうところ敵なしのスマホアプリ「ITニュース by lived...</td>\n",
       "      <td>kaden-channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>彼にあげたい韓国メンズコスメ、韓流俳優のような美肌男へ！年末の大イベント、クリスマスまであと...</td>\n",
       "      <td>peachy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>快適なスマホライフのための必須アプリ「マトリックス レボリューションズ」(c)Warner ...</td>\n",
       "      <td>livedoor-homme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>独女と上司の気になる関係人事異動の多い春は、職場の人間関係の悩みも増える時期。『an・an』...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0  新記録でロンドンに乗り込む“バタフライの女王”加藤ゆか3日に行われた競泳の日本選手権で、女子...    sports-watch\n",
       "1  家電チャンネルの記事も配信！向かうところ敵なしのスマホアプリ「ITニュース by lived...   kaden-channel\n",
       "2  彼にあげたい韓国メンズコスメ、韓流俳優のような美肌男へ！年末の大イベント、クリスマスまであと...          peachy\n",
       "3  快適なスマホライフのための必須アプリ「マトリックス レボリューションズ」(c)Warner ...  livedoor-homme\n",
       "4  独女と上司の気になる関係人事異動の多い春は、職場の人間関係の悩みも増える時期。『an・an』...  dokujo-tsushin"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data as tsv files.  \n",
    "test:dev:train = 2:2:6. To check the usability of finetuning, we also prepare sampled training data (1/5 of full training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
    "df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
    "df[len(df)*2 // 5:].to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)\n",
    "\n",
    "### 1/5 of full training data.\n",
    "# df[:len(df) // 5].to_csv( os.path.join(EXTRACTDIR, \"test.tsv\"), sep='\\t', index=False)\n",
    "# df[len(df) // 5:len(df)*2 // 5].to_csv( os.path.join(EXTRACTDIR, \"dev.tsv\"), sep='\\t', index=False)\n",
    "# df[len(df)*2 // 5:].sample(frac=0.2, random_state=23).to_csv( os.path.join(EXTRACTDIR, \"train.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune pre-trained model\n",
    "\n",
    "It will take a lot of hours to execute the following cells on CPU environment.  \n",
    "You can also use colab to recieve the power of TPU. You need to uplode the created data onto your GCS bucket.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zZH2GWe0U-7GjJ2w2duodFfEUptvHjcx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_PATH = '../model/asahi_output/model.ckpt-1300000'\n",
    "FINETUNE_OUTPUT_DIR = '../model/livedoor_asahi_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a trained SentencePiece model.\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f57af5a1d90>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../model/livedoor_asahi_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f57a301a860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Writing example 0 of 4421\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-1\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 大島 優子 が ここから どう 破 滅 していく のか ? ▁『 闇 金 ウ シ ジ マ くん 』 特 報 解禁 “ 闇 金 ” という 禁 断 の 題材 を リアル に 描いた 漫画 史上 最大の 問題 作 「 闇 金 ウ シ ジ マ くん 」 が 、 映画化 され 8 月 25 日から 公開 。 その 特 報 映像 が 遂 に 解禁 となった 。 債務 者を 非 情 に 追い込み 取り 立てる 最強 の 闇 金 ウ シ ジ マ には 若手 実力 派 俳優の 山田 孝 之 。 人生の 目的 を見 失 い 出会い カフェ に 出入り する フリーター 鈴木 未 來 には a k b 48 の 大島 優子 。 過去最大 イベント を成功させ て 人生を 一発 逆転 し 成 り 上 が ろうとする イベント サークル の代表 ・ 小川 純 には 『 荒川 アンダー ザ ブリッジ 』 の 林 遣 都 。 その他 、 崎 本 大 海 、 や べ きょう すけ が ドラマ シリーズ から 引き続き 登場 。 さらに 映画 版 新 キャスト には 、 新井 浩 文 、 岡田 義 徳 、 ム ロ ツ ヨシ 、 鈴 之助 、 内田 春 菊 、 黒沢 あす か など 個性的な 役者 が 揃 い 、 エ グ い 世界 を より 危険 に 彩 る 。 今回 、 映画 『 闇 金 ウ シ ジ マ くん 』 特 報 映像 が 解禁 となった が 、 わずか 30 秒 の 短い 映像 ながらも スリ ル 満 点 に 仕 上がっている 。 この 予告 編 では 、 大島 優子 はまだ きれいな 姿で いるが 、 本 作 では 母親の 借金 を 肩代わり したことで 、 ウ シ ジ マ から 取り 立て を受け 追い つめ られ ていく 役 。 女の子 たちが 金 のために 時間 を切り 売り する 「 出会い カフェ 」 に踏み 入れて 堕 ち ていく 。 ここから どう 変わる のか 見 ものである 。 さらに 、 原作 ファン には 嬉 しい 、 肉 蝮 ( に くま む し ) の 有名な 「 あの 」 シーン を思わせる カット が チ ラ リ と 登場する の も 見逃 せない 。 映画 『 闇 金 ウ シ ジ マ くん 』 は 8 月 25 日 ( 土 ) より 全国 公開 。 【 mo v i e ▁ en ter おすすめ 記事 】 ・ 石川 梨 華 、 ナンバー 1 ホステス を目指し 奮闘 ・ 美 山 加 恋 と 優 香 が 福島 に ! ▁ 絆 をつなぐ 大切 さを 映画 を通して 伝える ・ 福田 萌 、 ジャガイモ 型 ゴー スト に襲われた 恐怖 体験を 告白 ・ 長 澤 まさ み の 胸 元 に ハート が バク バク 、 モ テ キ 「 みゆき の部屋 & る み 子 の部屋 」 [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 3424 20088 12 18012 970 1988 7690 1586 326 734 19222 10111 156 683 516 590 403 6632 170 2608 2537 9468 1400 10111 156 1388 35 8803 1566 9 18801 16 11312 17 5227 6116 7600 2226 262 385 19 10111 156 683 516 590 403 6632 13 12 7 26463 206 61 37 180 340 1074 8 96 2608 2537 2581 12 31805 17 9468 263 8 5645 11333 2073 4440 17 29254 879 11084 28075 9 10111 156 683 516 590 403 56 2786 6604 919 19308 1228 857 644 8 11765 1950 1183 2153 106 8414 5798 17 10126 32 28857 1130 1649 0 56 2113 4908 4234 1360 9 3424 20088 8 26666 963 27622 66 14731 17464 2568 31 517 91 115 12 22717 963 7585 6059 21 2919 2222 56 207 8137 12613 1332 25956 170 9 480 25931 630 8 9444 7 667 95 48 281 7 22 1486 4657 15225 12 3212 3260 27 5033 5908 8 382 619 1506 104 30071 56 7 5694 1217 241 7 3102 502 822 7 633 411 624 15252 7 5378 7527 7 5015 473 3727 7 17143 18313 68 30 27435 10313 12 31612 106 7 597 1017 106 396 16 202 2511 17 3197 47 8 1781 7 619 207 10111 156 683 516 590 403 6632 170 2608 2537 2581 12 9468 263 12 7 4391 100 376 9 8034 2581 5588 19073 375 1120 145 17 3780 14014 8 87 24261 2413 52 7 3424 20088 2721 10169 7338 14477 7 95 385 52 8518 3586 16 24590 18599 7 683 516 590 403 27 879 3166 646 5259 9640 1005 1132 735 8 7960 2313 156 853 226 5646 2017 32 19 8414 5798 13 15359 20997 0 555 1132 8 18012 970 5051 326 198 12454 8 382 7 10285 1276 56 31436 2799 7 1824 0 15 17 11738 347 31 14 9 10393 19 2085 13 8604 21355 5857 12 617 360 330 20 15585 9 23 13705 5309 8 619 207 10111 156 683 516 590 403 6632 170 11 61 37 180 26 15 383 14 202 397 1074 8 660 22940 11113 1866 1519 10 9255 27368 21829 3051 43 21 1813 4964 2390 7 7532 24 29975 5111 21233 21 183 92 1111 3617 20 1755 859 12 1317 17 1202 10 16714 12271 13730 6869 619 2877 10225 21 2802 19329 7 21276 569 7375 1655 25212 9654 13814 24752 21 134 2707 4868 177 9 2628 80 17 12023 12 20387 20387 7 1159 1063 599 19 21688 15024 2771 47 177 81 15024 13 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: movie-enter (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-2\n",
      "INFO:tensorflow:tokens: [CLS] ▁ インタビュー : クリス チャン ・ ベール 「 演じる ことができる の は 役者 だけ 」 公開 当時 、 全米 歴代 2 位 という メガ ヒット を記録 し 、 世界 中で 社会 現象 を巻き 起こした 『 ダー ク ナイト 』 から 4 年 、「 誰もが 衝撃 を受ける 」 と ク リスト ファー ・ ノー ラン 監督が 自信を持って 贈 る 『 ダー ク ナイト ▁ ライ ジング 』 が 7 月 24 日 より 公開された 。 ゴ ッ サム シティ を舞台に 前 作 を超える 最後の 戦い を繰り広げ る 本 作 で 、『 バット マン ▁ ビ ギン ズ 』『 ダー ク ナイト 』 に続き 、 ブルース ・ ウェ イン / ダー ク ナイト を演じる クリス チャン ・ ベール に 、 本 作 に登場する キャラクター や ノー ラン 監督 について 語 って もらった 。 アン ・ ハ サ ウェイ なら 「 やれる 」 —— 本 作 の 脚本 について どう 思います か ? クリス チャン ・ ベール ( 以下 、 クリス チャン ) : 三 部 作 の 最後 を飾る の にふさわしい 内容 の 脚本 だと思った よ 。 描く だけ の価値 のある 物語 だった し 、 以前は ク リスト ファー ・ ノー ラン 監督が 果たして 3 本 目 を作る の かどうか 定 か ではなかった けれど 、 今回の 脚本 を読んで 、 なぜ 彼が 3 本 目 を作ろう と したのか 、 よく 理解 できた 気が した んだ 。 —— 前 作 で ブルース ・ ウェ イン / ダー ク ナイト は 、 肉体 的に も 精神的に も 大きな 傷 を負い ましたが 、 今回の ブルース はどう なって いますか ? クリス チャン : 今回の 彼 も やはり 肉体 的 、 精神的に 傷 を負って いる 状態 。 前 作 で 自ら が 選んだ 決断 のせいで 苦しんでいる んだ 。 ゴ ッ サム シティ の 希望 のために 選んだ 道 として 短い 間 は 問題 なかった が 、 真実 は やがて 白 日 の下 にさらされ る 。 ブルース にとっては 人生 で最も 厳しい 時 を迎える ことになる んだ 。 自 責 の 念 に押し 潰 される んだよ 。 そして 、 バット マン は 姿を消し てしまう の さ 。 —— そんな 彼の 前に 、 新たな キャラクター が現れ て 、 事態 が 変化 し ていきます よね 。 クリス チャン : アン ・ ハ サ ウェイ 演じる セ リー ナ は 不 作 法で 、 気 が強く て 、 厚 か ましく て 、 バット マン が ブルース であること も お 構 い なし という 女性 なんだ 。 でも ブルース は 、 彼女の そんな ところ に興味 を抱いた んだよ 。 何 しろ 大勢の 人に 正 体 を隠し ている だけに 、 彼 にとって 彼女は 非常に 興味 を そそ る 、 刺激 的で 、 ユーモア のある 女性 として 映る んだ 。 彼女は 、 再び 人々の 気力 を 蘇 らせる 人 な んだよ 。 —— キャ ット ウ ー マン を演じた アン ・ ハ サ ウェイ について どう 思います か ? クリス チャン : 最初の オーディション で の 脚本 の 読み 合わせ の後 、 僕は すぐに ノー ラン 監督の 方を 向 いた んだ 。 というのも 、 彼は いつも カメラ の 横 に 立っている から 、 果たして 僕の 立っている 位置 から 見え ている ものが 、 ちゃんと 彼 にも 見える かどうか わからなかった [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 9624 1022 20180 9414 21 26435 19 14460 3525 9 11 10313 390 13 1074 527 7 13356 10792 25 431 35 15034 7165 8003 31 7 396 1523 388 6431 15746 17089 207 3091 188 15386 170 27 33 36 59 21016 7016 1875 13 20 188 4288 9299 21 3477 1761 7728 26694 10875 47 207 3091 188 15386 10 3910 22180 170 12 49 37 251 26 202 12378 8 1092 782 12305 5760 14118 120 385 1715 1832 4388 13366 47 95 385 18 4165 6803 1064 10 959 22703 361 12540 3091 188 15386 170 5582 7 27699 21 10515 1030 318 3091 188 15386 16901 20180 9414 21 26435 17 7 95 385 20104 6246 22 3477 1761 356 109 1039 204 5777 8 1406 21 942 587 13668 329 19 20176 13 0 95 385 9 8486 109 970 17547 68 734 20180 9414 21 26435 15 2277 7 20180 9414 14 1022 79 143 385 9 8188 22748 9 12154 791 9 8486 21640 306 8 9413 390 18367 620 2521 67 31 7 13033 188 4288 9299 21 3477 1761 7728 14955 28 95 334 2549 9 1489 1419 68 7116 2649 7 875 8486 10551 7 1368 15464 28 95 334 20584 20 18397 7 666 1469 1387 4238 29 492 8 0 120 385 18 27699 21 10515 1030 318 3091 188 15386 11 7 20697 655 23 20580 23 503 1913 28142 14534 7 875 27699 5186 6054 24673 734 20180 9414 1022 875 4320 23 2993 20697 346 7 20580 1913 29815 290 1291 8 120 385 18 1667 12 6782 5295 29744 25672 492 8 1092 782 12305 5760 9 1156 853 6782 186 58 8034 355 11 262 336 12 7 11081 11 7524 350 26 6131 16553 47 8 27699 4129 2533 8068 1167 51 3435 2352 492 8 658 12543 9 3110 14063 30841 165 11360 8 1020 7 6803 1064 11 28531 2689 9 195 8 0 830 7023 814 7 1026 6246 20173 66 7 2245 12 2357 31 26507 10034 8 20180 9414 1022 1406 21 942 587 13668 14460 1008 947 384 11 456 385 9161 7 389 6830 66 7 3470 68 26914 66 7 6803 1064 12 27699 4407 23 136 22131 106 1744 35 261 5787 8 105 27699 11 7 14919 830 578 9962 25822 11360 8 549 6476 7647 625 215 622 15495 86 1870 7 4320 1097 12906 4733 5676 16 27882 47 7 5393 9509 7 18316 620 261 58 18729 492 8 12906 7 1688 5951 24720 16 12949 9954 39 70 11360 8 0 3898 1453 683 485 1064 20346 1406 21 942 587 13668 109 970 17547 68 734 20180 9414 1022 3537 24528 18 9 8486 9 2686 3195 5261 7 8561 2265 3477 1761 5215 9248 2256 160 492 8 23615 7 6525 1931 2525 9 780 17 10184 27 7 14955 13577 10184 7797 27 5429 86 5630 7 9664 4320 116 5503 1489 27102 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: movie-enter (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-3\n",
      "INFO:tensorflow:tokens: [CLS] ▁ ブラック マジック デザイン 、 h y p er de c k ▁ s s d ▁ レ コー ダー に ▁ タイム コード 、 d n x h d ▁ q u ic k t i me ▁ サポート を追加 【 ビデオ s al on 】 ブラック マジック デザイン は h y p er de c k ▁ 2.5 ▁ パブリック ベー タ 版 を リ リース した 。 今回の ソフト ウェ ア アップ デート では 、 エン ベッド タイム コード の サポート 、 q u ic k t i me ▁ への d n x h d ▁ 収録 、 s di ▁ カメラ による h y p er de c k ▁ s s d ▁ レ コー ダー への 収録 開始 機能 が 追加 される 。 h y p er de c k ▁ 2.5 ▁ パブリック ベー タ 版 ( ma c ▁ o s x / w in do w s ▁ 対応 ) は 同社 w e b サイト より 無償 で ダウンロード 可能 。 今回の アップ デート は b la c k ma g ic ▁ de s i g n ▁ s s d ▁ レ コー ダー の h y p er de c k ▁ s h u t t le ▁2 ▁ なら び に h y p er de c k ▁ st u di o ▁ の両 モデル に対応し ている 。 h y p er de c k ▁ 2.5 ▁ ソフト ウェ ア アップ デート は 、 h y p er de c k ▁ s h u t t le ▁ なら び に h y p er de c k st u di o ▁ に 、 タイム コード 機能 を追加 する 。 h d - s di ▁ ビデオ 信号 の 補助 データ スペース に エン ベッド されている タイム コード 情報 は 、 h y p er de c k ▁ の 非 圧縮 / a v i d ▁ d n x h d ▁ 圧縮 ビデオ ファイル に 書き 込まれる 。 ユーザー は 、 標準 r p - 18 8 h d ▁ プロ ト コル に基づいて 、 入力 ビデオ スト リー ム の タイム コード を 保存 する ことができ 、 収録 した ファイル に オリジナル の タイム コード 情報 を付けて 再生 すること が可能 だ 。 h y p er de c k ▁ s h u t t le ▁ なら び に h y p er de c k st u di o ▁ は 、 a v i d ▁ d n x h d ▁ 収録 ・ 再生 に対応し ており 、 a v i d ▁ から 完全な 認定 を受けている 。 h y p er de c k ▁ 2.5 ▁ ソフト ウェ ア は 、 d n x h d ▁ m x f ▁ フォー マット ファイル に加えて 、 d n x h d ▁ q u ic k t i me ▁ の 収録 ・ 再生 オ プ ション を追加 する 。 d n x h d ▁ ファイル を q u ic [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 11294 20553 1692 7 7384 4110 3178 9740 22967 3453 4908 10 1718 1718 4687 10 521 4123 3091 17 10 3665 13671 7 4687 6113 17727 7384 4687 10 31734 2742 17496 4908 3241 1866 19213 10 7050 20687 660 2574 1718 16882 10632 43 11294 20553 1692 11 7384 4110 3178 9740 22967 3453 4908 10 10636 10 27345 7713 386 1506 16 330 11070 29 8 875 2837 10515 267 2597 27202 52 7 3832 6310 3665 13671 9 7050 7 31734 2742 17496 4908 3241 1866 19213 10 97 4687 6113 17727 7384 4687 10 6291 7 1718 30312 10 2525 140 7384 4110 3178 9740 22967 3453 4908 10 1718 1718 4687 10 521 4123 3091 97 6291 1698 1520 12 3926 165 8 7384 4110 3178 9740 22967 3453 4908 10 10636 10 27345 7713 386 1506 15 9992 3453 10 2623 1718 17727 318 6910 4116 24926 6910 1718 10 972 14 11 1598 6910 1519 4234 3541 202 8628 18 28001 4786 8 875 2597 27202 11 4234 25808 3453 4908 9992 4465 17496 10 22967 1718 1866 4465 6113 10 1718 1718 4687 10 521 4123 3091 9 7384 4110 3178 9740 22967 3453 4908 10 1718 7384 2742 3241 3241 15058 111 10 329 994 17 7384 4110 3178 9740 22967 3453 4908 10 15653 2742 30312 2623 10 5198 3410 21115 86 8 7384 4110 3178 9740 22967 3453 4908 10 10636 10 2837 10515 267 2597 27202 11 7 7384 4110 3178 9740 22967 3453 4908 10 1718 7384 2742 3241 3241 15058 10 329 994 17 7384 4110 3178 9740 22967 3453 4908 15653 2742 30312 2623 10 17 7 3665 13671 1520 20687 32 8 7384 4687 141 1718 30312 10 2574 7357 9 2529 2759 4630 17 3832 6310 316 3665 13671 416 11 7 7384 4110 3178 9740 22967 3453 4908 10 9 2073 15831 318 2113 11113 1866 4687 10 4687 6113 17727 7384 4687 10 15831 2574 18542 17 1827 16353 8 25496 11 7 6626 7163 3178 141 184 61 7384 4687 10 1103 257 17347 6502 7 12262 2574 1655 947 633 9 3665 13671 16 2052 32 11886 7 6291 29 18542 17 6593 9 3665 13671 416 22258 1826 1007 8969 40 8 7384 4110 3178 9740 22967 3453 4908 10 1718 7384 2742 3241 3241 15058 10 329 994 17 7384 4110 3178 9740 22967 3453 4908 15653 2742 30312 2623 10 11 7 2113 11113 1866 4687 10 4687 6113 17727 7384 4687 10 6291 21 1826 21115 866 7 2113 11113 1866 4687 10 27 20564 1927 5820 8 7384 4110 3178 9740 22967 3453 4908 10 10636 10 2837 10515 267 11 7 4687 6113 17727 7384 4687 10 3583 17727 5957 10 6694 19689 18542 12546 7 4687 6113 17727 7384 4687 10 31734 2742 17496 4908 3241 1866 19213 10 9 6291 21 1826 519 1241 16241 20687 32 8 4687 6113 17727 7384 4687 10 18542 16 31734 2742 17496 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: kaden-channel (id = 2)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-4\n",
      "INFO:tensorflow:tokens: [CLS] ▁ センター 試験 終了 ! ▁ 受験生 ファン に 眞 鍋 か を り が 的確な アドバイス をしていた 【 話題 】 寒い 週末 、 毎年 恒例の センター 試験 が 行われていた 。 受験生 にとっては 大切な 日 。 ファン の 受験 を タレント の 眞 鍋 か を り も ツイッター で 応援 していた 。「 明日 の センター 試験 なので 自信 の 持てる 一言 ください 」 と 眞 鍋 に エール を求める ファン 。 彼女の 返答 は 「 助 詞 の使い方 間違って る から 現 国 マ ジ で 気をつけ な 」 だった 。 この 的確な アドバイス に 「 これは 良い 指摘 」 と ツ イー ト を 評価する 声 が多く 登場した 。 また 、 眞 鍋 に コメント をもらった 受験生 は ツイッター の フォ ロ ワー が 一気に 倍 になった ということだ 。 さ て 今回の 彼女の きつい エール は 生かされ た のだろうか 。 ■ 関連 記事 ・ f ac e bo o k 投稿 で 原因 発覚 ? ▁ イタリア の 豪華 客船 、 船長 がい いとこ 見せ たくて 事故 か ? 【 話題 】 ・ 傷 が 消える ケース は 世界 初 ! ▁ 日産 が 開発 の i p ho ne ケース に注目 【 売れ筋 チェック 】 ・ 日本 の首都 は 吉野 家で 首相は キ ティ ちゃん !? ▁ アン サイ クロ ペ ディア の 日本の 項目 が おもしろい 【 話題 】 ・ もはや 格闘 ドラマ ? ▁松 潤 主演 の 「 ラッキー セブン 」 は今後 が 楽しみ な 初回 1 6.3 % 【 話題 】 ・ 魁 !! ▁ ビデオ 道場 ▁ 2012 年 1 月号 【 ビデオ s al on 】 [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 289 1279 4565 1202 10 8178 1276 17 13516 5975 68 16 91 12 30825 7773 2067 660 3055 43 13660 4814 7 1354 11402 289 1279 12 24489 8 8178 4129 6681 26 8 1276 9 3107 16 10748 9 13516 5975 68 16 91 23 19483 18 1557 138 65 6085 9 289 1279 1960 2348 9 17367 8427 3703 13 20 13516 5975 17 14415 794 1276 8 14919 31359 11 19 2291 13889 16018 18453 47 27 727 178 403 590 18 15191 70 13 67 8 87 30825 7773 17 19 2115 2453 5636 13 20 624 8939 257 16 7760 902 1745 9094 8 212 7 13516 5975 17 4171 15991 8178 11 19483 9 8075 411 9440 12 4159 925 173 13950 8 195 66 875 14919 19516 14415 11 21959 42 3587 8 5054 1661 3051 21 5957 20217 1519 29141 2623 4908 3929 18 2897 10222 734 10 2699 9 22212 26979 7 9780 3966 26776 5367 15517 674 68 734 660 3055 43 21 1913 12 20548 1596 11 396 544 1202 10 14194 12 449 9 1866 3178 14802 13790 1596 15584 660 30043 3372 43 21 103 18146 11 4714 9075 2638 599 1395 1256 27980 10 1406 5709 4020 2031 19380 9 391 2301 12 14330 660 3055 43 21 15176 23531 3212 734 9500 4311 9770 9 19 27868 18611 13 7355 12 3283 70 11316 24 23750 130 660 3055 43 21 24118 13702 10 2574 13186 10 6238 36 24 21094 660 2574 1718 16882 10632 43 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: kaden-channel (id = 2)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-5\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 彼女 の香り は 、 柔軟 剤 の香り 都内で 一人暮らし をしている サ ナ エ さん ( 28 歳 ・ 医療 関連 ) は 、 同僚 の ミ ノリ さん ( 25 歳 ) が 返 してくれた タオル に 感激 した そうだ 。「 貸 したとき よりも フ ワ フ ワ になって いて 、 いい 香り が した んです 。 女性 ならではの 心 遣い だ と思いました 」 。 後 日 、 サ ナ エ さんが 気になる 香り の名前 を 聞いたところ 、 ミ ノリ さん からは 意外 が 答え が ... 。「 それ 、 柔軟 剤 の香り なんです 。 意外 といい 感じ ですよね 。 靴下 を 履 く とき も 、 ふ わ っと いい 香り が す んですよ 。 今まで 人工 的な 香り は 苦手 だった んですけど 、 この 香り は別 です 」 と 嬉 し そうに 話 してくれた 。 柔軟 剤 といえば 、 洗濯 物を 柔らかく 仕上げる ため のもの と考え がちだ が 、 このところ 、 香り に こだわり のある 柔軟 剤 が増えている 。「 タオル は フロー ラル 系 の香り の 柔軟 剤 、 洋服 は 夫 も 着 るので ハーブ 系 の香り の 柔軟 剤 を使って います 」 と話し てくれた の は ミナミ さん ( 28 歳 / 既 婚 ・ 派遣 ) 。 ただし 、 最初から 香り に こだわって 柔軟 剤 を選んだ の ではない という 。「 部屋 干し の 臭い 消し になる と聞いて ▁ 柔軟 剤 を使い 始めた んです 。 最初は 、 人気 のある 海外の メーカーの もの を買った んですけど 、 私には 香り が 強 すぎて 、 柔軟 剤 酔い を おこし かけ ました ( 笑 ) 。 それで 、 今は 、 もっぱら 国内 メーカーの もの を使って います 」( ミナミ さん ) 夜 、 洗濯 をして 室内 に 干 したり 、 花粉症 対策として 洗濯 物を 部屋 干し する 人 が増えている 昨今 、 悩み の タ ネ の 「 生 乾 き の 洗濯 物の 臭い 」 が 解決する なら と 、 防 臭 効果 を期待し て 柔軟 剤 を購入 する 人 は多い 。 しかも 、 ア ロ マ の良い 香り が したり 、 服 を ク シュ ク シュ する 加減 で 香り が広がった りと 、 香り の 面でも 柔軟 剤 は 進化 した のだから 、 女性たち の 興味 が集まる の も 、 もっとも な 話 だろう 。 結果として 、 今まで は 、 女性 から する 「 良い 香り 」 といえば 、 香 水 や オー デ コ ロン 、 シャン プー や リン ス 、 石 鹸 の香り など が一般的 だったが 、 最近は 、 ここに 柔軟 剤 の香り が 加わった 。 お 悩み 解決 & 洗濯 後 の香り で 、 女性は 幸せ になれる のだ 。 ただし 、 香り は 、 人 によって 好み が 分かれ る ことを忘れ てはいけない 。「 以前 、 母が 購入した 柔軟 剤 の香り で 、 気持ち が悪く なりました 」 と話し てくれた の は 、 イ オリ さん ( 26 歳 ・ 会社員 ) 。「 母が 柔軟 剤 を入れ 過ぎ ていた の も 原因 のひとつ ですが ... 。 さすがに 下着 からも シャツ からも 苦手な 香り が するので 、 耐え きれ なくなって 、 母 に使う の を止め てもらい ました 。 ▁ 家族で 香り の 好み が違う と 苦しい ですね [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 6357 14778 11 7 14826 3712 14778 17771 9951 1644 587 384 597 60 15 287 152 21 748 1661 14 11 7 4585 9 553 9418 60 15 180 152 14 12 2193 4479 9728 17 14110 29 1073 65 8985 14270 1784 670 1160 670 1160 804 824 7 393 6531 12 29 1437 8 261 13168 366 14756 40 13423 13 8 128 26 7 587 384 597 409 9593 6531 3404 16 29925 7 553 9418 60 1115 19115 12 2564 12 2788 65 778 7 14826 3712 14778 7465 8 19115 1977 1672 24110 8 28771 16 13911 168 1024 23 7 1090 576 2632 393 6531 12 199 6380 8 3973 4772 254 6531 11 15833 67 26691 7 87 6531 11323 161 13 20 31436 31 11159 856 4479 8 14826 3712 7801 7 12511 7984 29256 26208 142 6958 6582 19730 12 7 14823 7 6531 17 9013 620 14826 3712 5921 65 9728 11 25951 16774 956 14778 9 14826 3712 7 14889 11 377 23 755 19389 18678 956 14778 9 14826 3712 1350 1473 13 4079 2957 9 11 28709 60 15 287 152 318 13031 6275 21 1240 14 8 3804 7 16708 6531 17 26647 14826 3712 3991 9 862 35 65 3253 10555 9 25426 9840 163 16201 10 14826 3712 3395 880 1437 8 6417 7 1238 620 11629 8852 513 14793 26691 7 13904 6531 12 1087 10650 7 14826 3712 23163 16 17057 1932 415 15 5047 14 8 5831 7 1911 7 26384 1098 8852 513 1350 1473 112 28709 60 14 650 7 12511 2119 4843 17 8240 1504 7 30593 12972 12511 7984 3253 10555 32 39 5921 23682 7 4279 9 386 916 9 19 167 7283 162 9 12511 8397 25426 13 12 17422 329 20 7 2896 8386 1789 21372 66 14826 3712 10687 32 39 8517 8 3888 7 267 411 403 13452 6531 12 1504 7 2369 16 188 2978 188 2978 32 18851 18 6531 11283 9112 7 6531 9 22415 14826 3712 11 15740 29 6955 7 10881 9 5676 7689 9 23 7 7970 70 856 562 8 23658 7 3973 11 7 261 27 32 19 2453 6531 13 7801 7 859 146 22 2885 1209 362 3595 7 13008 27014 22 2128 157 7 280 0 14778 30 24119 1285 7 3564 7 6026 14826 3712 14778 12 12740 8 136 4279 1801 2771 12511 128 14778 18 7 3198 4910 12836 2772 8 3804 7 6531 11 7 39 694 12504 12 12695 47 27315 19455 65 6090 7 13004 13870 14826 3712 14778 18 7 1790 13584 14747 13 4079 2957 9 11 7 404 11397 60 15 275 152 21 712 14 65 13004 14826 3712 7389 3304 174 9 23 2897 7126 3726 2788 8 24307 20483 2899 5017 2899 27109 6531 12 17366 7 13638 21043 11963 7 1231 5359 9 11649 11172 415 8 10 13806 6531 9 12504 7440 20 5114 2382 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: dokujo-tsushin (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 4421\n",
      "INFO:tensorflow:  Batch size = 4\n",
      "INFO:tensorflow:  Num steps = 11052\n",
      "WARNING:tensorflow:From ../src/run_classifier.py:425: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (4, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (4, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (4,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (4,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (4, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (9, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (9,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-04-02 11:20:24.820673: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n",
      "2019-04-02 11:20:25.665978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-04-02 11:20:25.667161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:09:00.0\n",
      "totalMemory: 7.93GiB freeMemory: 7.82GiB\n",
      "2019-04-02 11:20:25.667189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2019-04-02 11:20:26.237451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-02 11:20:26.237489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2019-04-02 11:20:26.237510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2019-04-02 11:20:26.237936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7544 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from ../model/livedoor_asahi_output/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.01003\n",
      "INFO:tensorflow:examples/sec: 8.0401\n",
      "INFO:tensorflow:global_step/sec: 2.15722\n",
      "INFO:tensorflow:examples/sec: 8.62889\n",
      "INFO:tensorflow:global_step/sec: 2.15475\n",
      "INFO:tensorflow:examples/sec: 8.61899\n",
      "INFO:tensorflow:global_step/sec: 2.15436\n",
      "INFO:tensorflow:examples/sec: 8.61744\n",
      "INFO:tensorflow:global_step/sec: 2.15435\n",
      "INFO:tensorflow:examples/sec: 8.6174\n",
      "INFO:tensorflow:global_step/sec: 2.15326\n",
      "INFO:tensorflow:examples/sec: 8.61303\n",
      "INFO:tensorflow:global_step/sec: 2.1512\n",
      "INFO:tensorflow:examples/sec: 8.6048\n",
      "INFO:tensorflow:global_step/sec: 2.1519\n",
      "INFO:tensorflow:examples/sec: 8.6076\n",
      "INFO:tensorflow:global_step/sec: 2.15251\n",
      "INFO:tensorflow:examples/sec: 8.61006\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.9268\n",
      "INFO:tensorflow:examples/sec: 7.70719\n",
      "INFO:tensorflow:global_step/sec: 2.1516\n",
      "INFO:tensorflow:examples/sec: 8.60639\n",
      "INFO:tensorflow:global_step/sec: 2.15119\n",
      "INFO:tensorflow:examples/sec: 8.60475\n",
      "INFO:tensorflow:global_step/sec: 2.15122\n",
      "INFO:tensorflow:examples/sec: 8.60488\n",
      "INFO:tensorflow:global_step/sec: 2.15035\n",
      "INFO:tensorflow:examples/sec: 8.60141\n",
      "INFO:tensorflow:global_step/sec: 2.14995\n",
      "INFO:tensorflow:examples/sec: 8.59981\n",
      "INFO:tensorflow:global_step/sec: 2.15106\n",
      "INFO:tensorflow:examples/sec: 8.60424\n",
      "INFO:tensorflow:global_step/sec: 2.14924\n",
      "INFO:tensorflow:examples/sec: 8.59697\n",
      "INFO:tensorflow:global_step/sec: 2.15045\n",
      "INFO:tensorflow:examples/sec: 8.6018\n",
      "INFO:tensorflow:global_step/sec: 2.15142\n",
      "INFO:tensorflow:examples/sec: 8.6057\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.92954\n",
      "INFO:tensorflow:examples/sec: 7.71814\n",
      "INFO:tensorflow:global_step/sec: 2.15145\n",
      "INFO:tensorflow:examples/sec: 8.60582\n",
      "INFO:tensorflow:global_step/sec: 2.14943\n",
      "INFO:tensorflow:examples/sec: 8.59772\n",
      "INFO:tensorflow:global_step/sec: 2.14923\n",
      "INFO:tensorflow:examples/sec: 8.59693\n",
      "INFO:tensorflow:global_step/sec: 2.14854\n",
      "INFO:tensorflow:examples/sec: 8.59417\n",
      "INFO:tensorflow:global_step/sec: 2.14944\n",
      "INFO:tensorflow:examples/sec: 8.59777\n",
      "INFO:tensorflow:global_step/sec: 2.14921\n",
      "INFO:tensorflow:examples/sec: 8.59685\n",
      "INFO:tensorflow:global_step/sec: 2.15005\n",
      "INFO:tensorflow:examples/sec: 8.60021\n",
      "INFO:tensorflow:global_step/sec: 2.14962\n",
      "INFO:tensorflow:examples/sec: 8.59846\n",
      "INFO:tensorflow:global_step/sec: 2.14843\n",
      "INFO:tensorflow:examples/sec: 8.59373\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.92352\n",
      "INFO:tensorflow:examples/sec: 7.6941\n",
      "INFO:tensorflow:global_step/sec: 2.14609\n",
      "INFO:tensorflow:examples/sec: 8.58437\n",
      "INFO:tensorflow:global_step/sec: 2.14617\n",
      "INFO:tensorflow:examples/sec: 8.58469\n",
      "INFO:tensorflow:global_step/sec: 2.14743\n",
      "INFO:tensorflow:examples/sec: 8.58973\n",
      "INFO:tensorflow:global_step/sec: 2.14554\n",
      "INFO:tensorflow:examples/sec: 8.58216\n",
      "INFO:tensorflow:global_step/sec: 2.14545\n",
      "INFO:tensorflow:examples/sec: 8.58179\n",
      "INFO:tensorflow:global_step/sec: 2.14569\n",
      "INFO:tensorflow:examples/sec: 8.58277\n",
      "INFO:tensorflow:global_step/sec: 2.14539\n",
      "INFO:tensorflow:examples/sec: 8.58157\n",
      "INFO:tensorflow:global_step/sec: 2.14625\n",
      "INFO:tensorflow:examples/sec: 8.585\n",
      "INFO:tensorflow:global_step/sec: 2.14509\n",
      "INFO:tensorflow:examples/sec: 8.58034\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.91843\n",
      "INFO:tensorflow:examples/sec: 7.67374\n",
      "INFO:tensorflow:global_step/sec: 2.14481\n",
      "INFO:tensorflow:examples/sec: 8.57925\n",
      "INFO:tensorflow:global_step/sec: 2.14354\n",
      "INFO:tensorflow:examples/sec: 8.57414\n",
      "INFO:tensorflow:global_step/sec: 2.14406\n",
      "INFO:tensorflow:examples/sec: 8.57623\n",
      "INFO:tensorflow:global_step/sec: 2.14486\n",
      "INFO:tensorflow:examples/sec: 8.57945\n",
      "INFO:tensorflow:global_step/sec: 2.1467\n",
      "INFO:tensorflow:examples/sec: 8.5868\n",
      "INFO:tensorflow:global_step/sec: 2.14591\n",
      "INFO:tensorflow:examples/sec: 8.58364\n",
      "INFO:tensorflow:global_step/sec: 2.14573\n",
      "INFO:tensorflow:examples/sec: 8.5829\n",
      "INFO:tensorflow:global_step/sec: 2.14576\n",
      "INFO:tensorflow:examples/sec: 8.58302\n",
      "INFO:tensorflow:global_step/sec: 2.14552\n",
      "INFO:tensorflow:examples/sec: 8.5821\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.92133\n",
      "INFO:tensorflow:examples/sec: 7.68533\n",
      "INFO:tensorflow:global_step/sec: 2.14563\n",
      "INFO:tensorflow:examples/sec: 8.58252\n",
      "INFO:tensorflow:global_step/sec: 2.14554\n",
      "INFO:tensorflow:examples/sec: 8.58215\n",
      "INFO:tensorflow:global_step/sec: 2.14533\n",
      "INFO:tensorflow:examples/sec: 8.58131\n",
      "INFO:tensorflow:global_step/sec: 2.14467\n",
      "INFO:tensorflow:examples/sec: 8.57868\n",
      "INFO:tensorflow:global_step/sec: 2.14422\n",
      "INFO:tensorflow:examples/sec: 8.57688\n",
      "INFO:tensorflow:global_step/sec: 2.14416\n",
      "INFO:tensorflow:examples/sec: 8.57664\n",
      "INFO:tensorflow:global_step/sec: 2.1436\n",
      "INFO:tensorflow:examples/sec: 8.57439\n",
      "INFO:tensorflow:global_step/sec: 2.1429\n",
      "INFO:tensorflow:examples/sec: 8.57161\n",
      "INFO:tensorflow:global_step/sec: 2.14234\n",
      "INFO:tensorflow:examples/sec: 8.56936\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.91915\n",
      "INFO:tensorflow:examples/sec: 7.6766\n",
      "INFO:tensorflow:global_step/sec: 2.14406\n",
      "INFO:tensorflow:examples/sec: 8.57623\n",
      "INFO:tensorflow:global_step/sec: 2.14399\n",
      "INFO:tensorflow:examples/sec: 8.57595\n",
      "INFO:tensorflow:global_step/sec: 2.14386\n",
      "INFO:tensorflow:examples/sec: 8.57542\n",
      "INFO:tensorflow:global_step/sec: 2.14241\n",
      "INFO:tensorflow:examples/sec: 8.56964\n",
      "INFO:tensorflow:global_step/sec: 2.14331\n",
      "INFO:tensorflow:examples/sec: 8.57324\n",
      "INFO:tensorflow:global_step/sec: 2.14204\n",
      "INFO:tensorflow:examples/sec: 8.56817\n",
      "INFO:tensorflow:global_step/sec: 2.14224\n",
      "INFO:tensorflow:examples/sec: 8.56897\n",
      "INFO:tensorflow:global_step/sec: 2.14249\n",
      "INFO:tensorflow:examples/sec: 8.56996\n",
      "INFO:tensorflow:global_step/sec: 2.14318\n",
      "INFO:tensorflow:examples/sec: 8.5727\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.91268\n",
      "INFO:tensorflow:examples/sec: 7.65073\n",
      "INFO:tensorflow:global_step/sec: 2.14267\n",
      "INFO:tensorflow:examples/sec: 8.57068\n",
      "INFO:tensorflow:global_step/sec: 2.14174\n",
      "INFO:tensorflow:examples/sec: 8.56694\n",
      "INFO:tensorflow:global_step/sec: 2.14219\n",
      "INFO:tensorflow:examples/sec: 8.56877\n",
      "INFO:tensorflow:global_step/sec: 2.14126\n",
      "INFO:tensorflow:examples/sec: 8.56503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.14171\n",
      "INFO:tensorflow:examples/sec: 8.56684\n",
      "INFO:tensorflow:global_step/sec: 2.14067\n",
      "INFO:tensorflow:examples/sec: 8.5627\n",
      "INFO:tensorflow:global_step/sec: 2.14119\n",
      "INFO:tensorflow:examples/sec: 8.56476\n",
      "INFO:tensorflow:global_step/sec: 2.14177\n",
      "INFO:tensorflow:examples/sec: 8.56708\n",
      "INFO:tensorflow:global_step/sec: 2.14124\n",
      "INFO:tensorflow:examples/sec: 8.56497\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.91379\n",
      "INFO:tensorflow:examples/sec: 7.65516\n",
      "INFO:tensorflow:global_step/sec: 2.14072\n",
      "INFO:tensorflow:examples/sec: 8.5629\n",
      "INFO:tensorflow:global_step/sec: 2.1406\n",
      "INFO:tensorflow:examples/sec: 8.56238\n",
      "INFO:tensorflow:global_step/sec: 2.13693\n",
      "INFO:tensorflow:examples/sec: 8.54771\n",
      "INFO:tensorflow:global_step/sec: 2.13942\n",
      "INFO:tensorflow:examples/sec: 8.55766\n",
      "INFO:tensorflow:global_step/sec: 2.13943\n",
      "INFO:tensorflow:examples/sec: 8.55773\n",
      "INFO:tensorflow:global_step/sec: 2.13967\n",
      "INFO:tensorflow:examples/sec: 8.5587\n",
      "INFO:tensorflow:global_step/sec: 2.14027\n",
      "INFO:tensorflow:examples/sec: 8.5611\n",
      "INFO:tensorflow:global_step/sec: 2.13952\n",
      "INFO:tensorflow:examples/sec: 8.55807\n",
      "INFO:tensorflow:global_step/sec: 2.1393\n",
      "INFO:tensorflow:examples/sec: 8.55721\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.92001\n",
      "INFO:tensorflow:examples/sec: 7.68006\n",
      "INFO:tensorflow:global_step/sec: 2.13879\n",
      "INFO:tensorflow:examples/sec: 8.55517\n",
      "INFO:tensorflow:global_step/sec: 2.13923\n",
      "INFO:tensorflow:examples/sec: 8.55694\n",
      "INFO:tensorflow:global_step/sec: 2.13603\n",
      "INFO:tensorflow:examples/sec: 8.54412\n",
      "INFO:tensorflow:global_step/sec: 2.13859\n",
      "INFO:tensorflow:examples/sec: 8.55436\n",
      "INFO:tensorflow:global_step/sec: 2.13681\n",
      "INFO:tensorflow:examples/sec: 8.54723\n",
      "INFO:tensorflow:global_step/sec: 2.13628\n",
      "INFO:tensorflow:examples/sec: 8.54514\n",
      "INFO:tensorflow:global_step/sec: 2.13722\n",
      "INFO:tensorflow:examples/sec: 8.54888\n",
      "INFO:tensorflow:global_step/sec: 2.13841\n",
      "INFO:tensorflow:examples/sec: 8.55363\n",
      "INFO:tensorflow:global_step/sec: 2.13639\n",
      "INFO:tensorflow:examples/sec: 8.54556\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.9126\n",
      "INFO:tensorflow:examples/sec: 7.65039\n",
      "INFO:tensorflow:global_step/sec: 2.13584\n",
      "INFO:tensorflow:examples/sec: 8.54334\n",
      "INFO:tensorflow:global_step/sec: 2.13718\n",
      "INFO:tensorflow:examples/sec: 8.54872\n",
      "INFO:tensorflow:global_step/sec: 2.13753\n",
      "INFO:tensorflow:examples/sec: 8.55011\n",
      "INFO:tensorflow:global_step/sec: 2.13594\n",
      "INFO:tensorflow:examples/sec: 8.54376\n",
      "INFO:tensorflow:global_step/sec: 2.13644\n",
      "INFO:tensorflow:examples/sec: 8.54577\n",
      "INFO:tensorflow:global_step/sec: 2.13654\n",
      "INFO:tensorflow:examples/sec: 8.54614\n",
      "INFO:tensorflow:global_step/sec: 2.13611\n",
      "INFO:tensorflow:examples/sec: 8.54446\n",
      "INFO:tensorflow:global_step/sec: 2.13729\n",
      "INFO:tensorflow:examples/sec: 8.54915\n",
      "INFO:tensorflow:global_step/sec: 2.13629\n",
      "INFO:tensorflow:examples/sec: 8.54518\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.90983\n",
      "INFO:tensorflow:examples/sec: 7.6393\n",
      "INFO:tensorflow:Saving checkpoints for 11052 into ../model/livedoor_asahi_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8840297.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "INFO:tensorflow:Writing example 0 of 1473\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: dev-1\n",
      "INFO:tensorflow:tokens: [CLS] ▁ オ リン パス イメージ ング 、 防 水 ・ 耐 衝撃 など を備えた コンパクト デジタルカメラ 5 機種 を 発売 【 売れ筋 チェック 】 オ リン パス イメージ ング 株式会社 は 、 コンパクト デジタルカメラ の新 機種 として 、 ス タイ リ ッシュ な ボディー に 防 水 ・ 耐 衝撃 ・ 耐 低温 機能 を備えた 「 ol y m p us ▁ st y lu s ▁ t g − 6 25 」 を含む コンパクト デジタルカメラ 5 機種 を 、 2012 年 8 月 31 日から 順次 発売する 。 ■ 各 機種 の主な 特 長 「 ol y m p us ▁ st y lu s ▁ t g − 6 25 」 1 . ス タイ リ ッシュ な ボディー に 、 防 水 5 m 、 耐 衝撃 1.5 m 、 耐 低温 − 10 ° C の 性能 を 搭載 。 料理 や パーティー など 日常 の 何 気 ない シーン に加え 、 海 や 山 など アク ティブ な シーン でも 安心して 撮影 できる 。 2 . 高 感 度 ・ 高 画 質 ・ 高速 オート フォー カス を実現する 「 i h s テクノロジー ( ※ 4 ) 」 で 、 夜景 や 逆 光 でも 美しい 写真 を 残 せる 。 3 . ピン ト 合わせ の 精度 を向上させ る 補助 光 「 a f イル ミネ ーター 」 により 、 暗い シーン で の 撮影 に 便利 。「 ol y m p us ▁ st y lu s ▁ v h − 5 15 」 1 . 高 感 度 ・ 高 画 質 ・ 高速 オート フォー カス を実現する 「 i h s テクノロジー 」 で 、 夜景 や 逆 光 でも 美しい 写真 を 残 せる 。 2 . 滑 ら か で 高 画 質 な フル ハイビジョン ムー ビー が 、 長時間 録画 可能 。 3 . 鮮やかな 色彩 にする 「 ポップ 」 や 、 光 の効果 で やわらか い 雰囲気 に 写し 出す 「 ウェ ディング 」 など 、 さまざまな 演出 の 撮影 ができる 12 種類の 「 マジック フィルター 」 を楽しめる 。「 ol y m p us ▁ st y lu s ▁ v h − 4 10 」 1 . 3.0 型 液晶 タッチ パネル の 採用 により 、 ズ ーム の調整 や 色合い 、 明るさ などを 直 感 的に 操作 可能 。 2 . 手 ぶれ を ダブル で 抑え る 「 d u al ▁ is 」 により 、 手 ぶれ ・ 被 写 体 ぶれ を 効果的 に 低 減 する 。 3 . 「 ビュー ティー モード 」 の 「 メイ ク アップ 機能 」 により 、 撮影した 画像 に チー ク や つけ まつ 毛 を加えた り 、 瞳 の色 や 大きさ を変える など 、 人物 の 顔を より 美しく 仕上げ ることができる 。「 ol y m p us ▁ st y lu s ▁ s p − 8 20 u z 」 1 . 手のひら サイズ の 小型 ボ ディ に 、 広 角 2 2.4 m m から 望 遠 89 6 m m の 光 学 40 倍 ウル トラ [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 519 2128 4461 2443 6859 7 2896 146 21 15971 7016 30 17276 23499 26513 38 14196 16 2637 660 30043 3372 43 519 2128 4461 2443 6859 10328 11 7 23499 26513 3449 14196 58 7 157 1468 330 8115 70 28295 17 2896 146 21 15971 7016 21 15971 25727 1520 17276 19 22798 4110 3583 3178 25167 10 15653 4110 29909 1718 10 3241 4465 0 41 180 13 1273 23499 26513 38 14196 16 7 6238 36 61 37 453 340 11229 13793 8 5054 243 14196 9477 2608 134 19 22798 4110 3583 3178 25167 10 15653 4110 29909 1718 10 3241 4465 0 41 180 13 24 189 157 1468 330 8115 70 28295 17 7 2896 146 38 3583 7 15971 7016 9183 3583 7 15971 25727 0 45 0 626 9 12792 16 14192 8 1006 22 5321 30 4810 9 549 389 148 8604 2353 7 281 22 92 30 12308 16538 70 8604 105 9347 653 238 8 25 189 119 638 300 21 119 1316 1724 21 4618 20759 6694 9921 20462 19 1866 7384 1718 27797 15 9803 33 14 13 18 7 29843 22 2834 224 105 3551 127 16 2002 2851 8 28 189 7828 257 3195 9 21714 29567 47 2529 224 19 2113 5957 12282 20872 12078 13 2013 7 9675 8604 18 9 653 17 10210 65 22798 4110 3583 3178 25167 10 15653 4110 29909 1718 10 11113 7384 0 38 121 13 24 189 119 638 300 21 119 1316 1724 21 4618 20759 6694 9921 20462 19 1866 7384 1718 27797 13 18 7 29843 22 2834 224 105 3551 127 16 2002 2851 8 25 189 5690 74 68 18 119 1316 1724 70 3179 30513 12095 3481 12 7 15542 21235 4786 8 28 189 13529 12686 2259 19 26549 13 22 7 224 11152 18 25136 106 3138 17 17651 1262 19 10515 10585 13 30 7 3542 3280 9 653 2081 102 5766 19 20553 29842 13 18964 65 22798 4110 3583 3178 25167 10 15653 4110 29909 1718 10 11113 7384 0 33 45 13 24 189 19300 569 17303 11239 4005 9 1324 2013 7 361 13879 11823 22 24378 7 21199 277 543 638 655 4762 4786 8 25 189 179 28957 16 15208 18 8266 47 19 4687 2742 16882 10 15132 13 2013 7 179 28957 21 8467 4167 622 28957 16 17954 17 2246 747 32 8 28 189 19 13269 5112 24626 13 9 19 8666 188 2597 1520 13 2013 7 6233 7160 17 15470 188 22 2034 5885 2080 7944 91 7 18550 10250 22 9357 7009 30 7 3100 9 4409 202 15682 11853 8808 65 22798 4110 3583 3178 25167 10 15653 4110 29909 1718 10 1718 3178 0 61 84 2742 14102 13 24 189 20068 7169 9 3738 1144 1736 17 7 586 1507 25 16390 3583 3583 27 2789 2116 1835 41 3583 3583 9 224 412 210 925 9519 4152 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: kaden-channel (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: dev-2\r\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 露 骨 すぎる !? サム ス ン が i p ho ne は 古い と アン チ キャンペーン を展開 【 話題 】 サム ス ン が 行っている f ac e bo o k で の キャンペーン が 露 骨 だと 話題 になっている 。 サム ス ン は 自社 の スマートフォン 「 ga la x y ▁ s ▁ i i 」 は 最先端 だが アップル 社の 「 i p ho ne 」 はもう 古い と 伝える 画像 を掲載 している 。「 オール ド スクール 」 と 表現 された i p ho ne のそばに は 糸 電話 や 古い タイプの 携帯電話 が置かれ ている 皮肉 たっぷり な 出来 栄 え だ 。 この キャンペーン について 、「 サム ス ン は アップル を 羨 まし が っていて 、 やっている ことが 子ども だ 」 や 「 サム ス ン の 商品 は 好き だが さすがに やり すぎ 」 という声 が あがっている 。 あまりに 露 骨 な この 広告 は もはや ジョー ク だ 。 s am s un g ▁ c on t in u es ▁ w i th ▁ an t i - a p p le ▁ r an t ▁ on ▁ f ac e bo o k , ▁ sa y s ▁ i p ho ne ▁ is ▁ “ ol d ▁ s c ho ol ” ■ 関連 記事 サム ス ン が アップル に 逆転 勝訴 ! ▁ オーストラリア で の販売 差し止め 取り消し ■ 関連 記事 ・ 【 記事 連動 】 音 の 編集 講座 「 音 量の 合わせ 方 」 【 ビデオ s al on 】 ・ k d di が i p ho ne 向け アプリ 「 a u お客 さま サポート 」 ▁ を リ リース 【 話題 】 ・ 電子 書籍 市場 を こ っ そり 支える の は 女の子 の エ ッチ な 願望 ? 【 話題 】 ・ 連載 ● 極 ・ ト 書き 一行 の カット 割り ! ▁第 6 回 【 ビデオ s al on 】 ・ 白 物 家電 は やっぱり 店頭 買い が主流 ! ▁ 洗濯機 の ネット 通販 は たった 3.2 % 【 話題 】 [SEP]\r\n",
      "INFO:tensorflow:input_ids: 4 10 5453 1612 4140 27980 12305 157 798 12 1866 3178 14802 13790 11 3333 20 1406 617 6080 10492 660 3055 43 12305 157 798 12 16636 5957 20217 1519 29141 2623 4908 18 9 6080 12 5453 1612 1591 3055 728 8 12305 157 798 11 7511 9 22931 19 20435 25808 17727 4110 10 1718 10 1866 1866 13 11 21252 131 24192 4417 19 1866 3178 14802 13790 13 12256 3333 20 10225 7160 12404 73 65 9343 532 5654 13 20 1575 94 1866 3178 14802 13790 25707 11 2532 190 22 3333 17587 3440 17072 86 18340 9956 70 6170 938 557 40 8 87 6080 109 59 12305 157 798 11 24192 16 0 12002 12 17750 7 8065 407 731 40 13 22 19 12305 157 798 9 1165 11 2920 131 24307 2738 3134 13 7201 12 25221 8 16465 5453 1612 70 87 2430 11 15176 18297 188 40 8 1718 23999 1718 22398 4465 10 3453 10632 3241 4116 2742 17018 10 6910 1866 18997 10 8481 3241 1866 141 2113 3178 3178 15058 10 7163 8481 3241 10 10632 10 5957 20217 1519 29141 2623 4908 150 10 18737 4110 1718 10 1866 3178 14802 13790 10 15132 10 1400 22798 4687 10 1718 3453 14802 22798 1388 5054 1661 3051 12305 157 798 12 24192 17 2568 24692 1202 10 6189 18 4299 13915 8272 5054 1661 3051 21 660 3051 15600 43 752 9 4273 1477 19 752 11453 3195 363 13 660 2574 1718 16882 10632 43 21 4908 4687 30312 12 1866 3178 14802 13790 1671 24318 19 2113 2742 16021 3003 7050 13 10 16 330 11070 660 3055 43 21 2952 12617 988 16 244 1003 21681 18039 9 11 7960 9 597 6727 70 30771 734 660 3055 43 21 6392 2825 2164 21 257 1827 17741 9 5857 4929 1202 852 41 90 660 2574 1718 16882 10632 43 21 350 317 9623 11 7209 7954 2879 20938 1202 10 26640 9 1396 26359 11 4830 21798 130 660 3055 43 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: kaden-channel (id = 2)\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: dev-3\r\n",
      "INFO:tensorflow:tokens: [CLS] ▁ “ あなたの 人生 史上 、 最高の 実 話 ” ▁ サンド ラ ・ ブロック 最高の 演技 が 待 望 の リ リース 全米 で 興行 収入 2 億ドル を超える 大ヒット を記録 し 、 主演 の サンド ラ ・ ブロック が 、 本 年度 アカデミー 賞 主演 女優 賞受賞 をした 映画 「 し あわせ の 隠れ 場所 」 の ブルー レイ & d v d セット が 、 7 月 21 日 ( 水 ) より リ リース されます 。「 し あわせ の 隠れ 場所 」 は 、 サンド ラ ・ ブロック 演じる リー ・ アン と 、 孤独 な 黒人 青年 と の 心の 触れ合い を描いた ヒュー マン ・ ドラマ 。 全米 スポーツ で 1 番 人気 を誇る n f l ( n ation al ▁ f o o t b all ▁ le a g u e ) の花 形 ルー キー 、 マイケル ・ オ アー 選手の 半 生 を描いた 感動 の実 話 です 。 父親の 顔 も 知らず に 育ち 、 母親 と は 引き 離 され 、 家族の 温 かみ を 知らず に 生きてきた マイケル の 能力 を見 抜き 、 フットボール の 選手 として の 才能 を 開花 させ ていく リー ・ アン の姿 は 自立 した 1 人 の女性 であり 、 無償 の 愛情 を注ぐ 母親 であり 、 女性 なら 誰 し も が 感動 を覚える でしょう 。 アカデミー 賞 の 他に も 、 ゴールデン ・ グローブ 賞 ドラマ 部門 主演 女優 賞受賞 、 放送 映画 批評 家 協会 主演 女優 賞受賞 を 受賞 しており 、 サンド ラ ・ ブロック の 俳優 人生 集大成 とも言える 、 見事な 演技 を 観 て 、 自分の “ し あわせ ” について 考えて みて はいかが でしょうか ? 「 し あわせ の 隠れ 場所 」 ストーリー 夫と 娘 、 息子の 4 人で 幸せ に 暮らす 裕 福 な 白 人 家庭 の 夫人 リー ・ アン 。 彼女は ある 凍 て つく ような 真 冬の 夜 、 ひとり 寂 しく t シャツ と 短 パン で 歩いている 巨 漢 の 黒人 少年 に目を 止め 、 声をかける 。 そして 、 マイケル と 名 乗る その 少年 を放って おけ なくなり 、 ひと まず 自宅 へ 彼 を招き 入れる ことに 。 マイケル は 父親の 顔 も 知らず に 育ち 、 母親 と は 引き 離 され 、 住む 場所 や 学校 も 転 々と する 劣 悪 な 境 遇 に 置かれ ていた 。 そんな 彼 に 、 はじめ は 憐 れ み だけ を感じ ていた リー ・ アン 。 しかし 、 マイケル の 瞳 の中に 輝き を見つけた 彼女は 後 見 人 になると 決心 、 自分の 部屋 と 教育 の場 を与え 、 改めて 家族 の一員として マイケル を迎え 入れる の だった 。 また リー ・ アン はある 時 、 大 柄 であり ながら 敏 捷 な 肉体 と 仲間 を 危険 から 守る 保護 本 能 に 秀 で た 心 を持つ マイケル に アメリカン ・ フットボール の 才能 を見 出す 。 こうして アメ フ ト に取り組む マイケル は たちまち その 能力 を発揮 し 、 一 躍 注目 選手 として 成長 していく の だが ... 。 ・ ワーナー ・ ホーム ・ ビデオ 「 [SEP]\r\n",
      "INFO:tensorflow:input_ids: 4 10 1400 10752 2533 7600 7 7737 457 856 1388 10 26725 360 21 2187 7737 6293 12 10587 2789 9 330 11070 13356 18 23062 2050 25 5447 1715 26822 8003 31 7 9770 9 26725 360 21 2187 12 7 95 935 13119 652 9770 8219 25457 702 619 19 31 9076 9 8746 705 13 9 6624 3776 2771 4687 11113 4687 1995 12 7 49 37 234 26 15 146 14 202 330 11070 14950 65 31 9076 9 8746 705 13 11 7 26725 360 21 2187 14460 947 21 1406 20 7 13120 70 15357 3337 20 9 3448 29828 3376 19649 1064 21 3212 8 13356 891 18 24 648 1238 10504 6113 5957 10553 15 6113 31253 16882 10 5957 2623 2623 3241 4234 31543 10 15058 2113 4465 2742 1519 14 2930 758 4944 4815 7 22322 21 519 3914 4224 1158 167 3376 5080 7299 856 161 8 10142 1018 23 12992 17 9330 7 2458 20 11 1275 4214 206 7 5575 3026 5640 16 12992 17 26171 22322 9 1658 1183 2880 7 18989 9 337 58 9 16087 16 8528 1088 1132 947 21 1406 3759 11 4802 29 24 39 1928 865 7 8628 9 14954 26607 2458 865 7 261 329 7237 31 23 12 5080 22865 1954 8 13119 652 9 10855 23 7 24537 21 31356 652 3212 1863 9770 8219 25457 7 986 619 21245 231 603 9770 8219 25457 16 5735 909 7 26725 360 21 2187 9 6872 2533 27840 24758 7 20582 6293 16 2324 66 7 490 1400 31 9076 1388 109 4821 7296 25937 7418 734 19 31 9076 9 8746 705 13 12678 14413 2146 7 12195 33 828 4910 17 7325 1059 895 70 350 39 1123 9 10162 947 21 1406 8 12906 225 13047 66 1743 602 323 5009 650 7 5064 16340 4464 3241 5017 20 4711 1721 18 20642 5175 8161 9 15357 1054 13767 5969 7 24491 8 1020 7 22322 20 228 19554 96 1054 21170 24773 5040 7 2282 998 2106 83 4320 11258 11834 1531 8 22322 11 10142 1018 23 12992 17 9330 7 2458 20 11 1275 4214 206 7 7738 705 22 322 23 2161 5863 32 10543 1654 70 3462 29250 17 11357 174 8 830 4320 17 7 7380 11 0 826 177 390 4513 174 947 21 1406 8 236 7 22322 9 18550 2074 15190 8246 12906 128 198 39 2604 26297 7 490 3253 20 265 4372 4112 7 2559 775 25039 22322 4901 11834 9 67 8 212 947 21 1406 3521 51 7 48 2960 865 239 1436 29611 70 20697 20 1857 16 2511 27 10297 1610 95 1883 17 858 18 42 366 904 22322 17 17197 21 18989 9 16087 1183 1262 8 15987 16811 670 257 2594 22322 11 28838 96 1658 10344 31 7 53 7632 5298 337 58 1614 1586 9 131 2788 8 21 31455 21 1938 21 2574 19 5\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: peachy (id = 5)\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: dev-4\r\n",
      "INFO:tensorflow:tokens: [CLS] ▁ スマート で 美しい “ サイ フ 美 人 ” は ロンドン っ 娘 ! ▁ その理由 は カード にあり ! あい かわ らず 厳しい 残 暑 が 続いて います が 、 もう まもなく 8 月 も 終わり 。 さ て 、 みなさん 夏休み は 何を されました か ? 海外旅行 、 夏の セール と 時間も お金 も いろんな 使い道 があったこと だと は 思います 。 とくに お金 となれば 、 多くの人が 夏の ボーナス を 目 論 んで 夏休み を楽しんだ か と思います 。 思わず 使い すぎ てしまった となれば 、 一応 精 算 して おか なければ 。 女 た るもの 、 お 財布 の管理 くらい しっかり できて ないと ...... え 、 あれ ? ▁ なんか 想像 以上に 現金 がない 。 あれ ー 、 何 に使った っけ か なぁ ......。 いくら 気をつけ ていて も 、 現金 で の 支出 管理 はなかなか 難しい もの 。 財布 に入っている と つい つい 使って しまう なら 財布 に お金 を持た なければ いい ! ▁ と思い たい が 、 フィナンシャル プラン ナー の 山口 京子 氏は こう話す 。「 実は “ 最小限 の 現金 だけ 入れて おけば 、 お金 が 貯 まる ” というのは 大きな 誤解 です 。 慣れ て しま えば 、 計画 性 が 薄れ てくる 可能性 があります 。 at m で 下ろす 金額 と 回数 を決め 、 手 持ち の 現金 の 適正 額 を設定 し 、『 つか う お金 』 、『 貯 める お金 』 、『 一 定額 支払う お金 』 を きっちり 分けて 、 用途 に あう 決済 方法 を選ぶ ことが 家計 管理 を スマート 化する 近 道 と なります 」 と のこと 。 では 、 そんな 支出 管理 の プロ である 山口 氏 お ス ス メ の 方法は 、 デ ビット カード 。 利用 した 時点で 即時 に 自分の 銀行口座 から 引き 落 とされる ため 、 現金 と同じ 感覚 で 支払い が可能 。 利用 履 歴 は インターネットで 即時 に 確認 することができる と 、 誰でも 安心して 使える 優 れ もの なのである 。 ▁ 今は j - de b it ( ジェイ デ ビット カード ) に加え 、 v is a からも デ ビット カード が出ている 。 この v is a デ ビット カード は 、 v is a ▁ マーク が 掲 出 されている 世界中の お店 で 営業時間 内 いつでも 使える という わけ 。 その 優秀 さを 証明 すべ く 山口 氏が 行った 実験 が 、「 現金 1 万円 + デ ビット カード で どれくらい 生活 できるか 」 。 これは いわゆる “ 節約 生活 ” ではなく 、 電子 決済 で どの程度 暮らせる か を 試 したもの 。 使用 したのは v is a デ ビット カード 。 普通 に 日々 を 過ごし てみると 、 事実 v is a マーク の お店 は 想像 以上 にあり 、 現金 を 使わ なければいけない シーン は そんなに なかった のである 。 結果 、 1 万円の 現金 を使い 切る には 、 なんと 20 日間 も かかった のである 。「 カード には 抵抗 がある 」 という 人も ご 安心 、 デ ビット カード は 即 日 決済 。 しかも インターネットで 履 歴 を すぐに 確認 できる の で 、 レ シート 要 らず 、 家計 簿 をつける 手間 も 省 ける って ワ [SEP]\r\n",
      "INFO:tensorflow:input_ids: 4 10 29023 18 3551 1400 5709 670 183 39 1388 11 4805 1003 2146 1202 10 19852 11 1970 4603 1202 2950 4022 2780 1167 2002 12568 12 4799 1473 12 7 898 13355 61 37 23 4420 8 195 66 7 7056 4099 11 5593 14370 68 734 19710 7 3423 14871 20 15100 3292 23 5208 21732 17412 1591 11 17547 8 5391 3292 18799 7 13351 3423 9893 16 334 1108 1668 4099 8375 68 1981 8 9375 3529 3134 3314 18799 7 22074 2198 6139 69 5264 2086 8 663 42 11943 7 136 9903 10757 2650 3332 10916 4064 2584 557 7 3685 734 10 9994 5548 6454 1522 760 8 3685 485 7 549 12914 21392 68 24945 1525 7605 15191 6907 23 7 1522 18 9 2445 566 17400 3263 513 8 9903 13887 20 3709 3709 6804 4880 329 9903 17 3292 26480 2086 393 1202 10 3797 187 12 7 31265 4424 2992 9 786 13035 276 25670 65 3997 1400 18588 9 1522 390 20997 23092 7 3292 12 19859 2109 1388 4384 503 11645 161 8 11112 66 5847 12871 7 343 294 12 15731 4666 2350 3394 8 21654 3583 18 20153 4260 20 6824 3896 7 179 1293 9 1522 9 11382 1093 15331 31 4165 3378 260 3292 170 4165 19859 2966 3292 170 4165 53 18079 13604 3292 170 16 24081 23591 7 16214 17 8990 22135 1447 5685 407 11231 566 16 29023 7567 1548 186 20 13242 13 20 4704 8 52 7 830 2445 566 9 1103 155 786 122 136 157 157 773 9 15109 7 1209 24041 1970 8 820 29 4105 20456 17 490 25086 27 1275 2338 889 142 7 1522 1302 3084 18 6390 8969 8 820 13911 6504 11 13201 20456 17 1306 20409 20 7 19633 9347 4482 1755 826 513 23123 8 10 1911 11885 141 22967 4234 14283 15 19569 1209 24041 1970 14 2353 7 11113 15132 2113 2899 1209 24041 1970 4402 8 87 11113 15132 2113 1209 24041 1970 11 7 11113 15132 2113 10 3689 12 31826 311 316 21507 23310 18 23390 194 12832 4482 35 4849 8 96 11390 6869 9002 14346 168 786 1086 3656 1673 12 59 1522 24 139 7154 1209 24041 1970 18 28811 331 9311 13 8 2115 9164 1400 13608 331 1388 1330 7 2952 22135 18 19521 29363 68 16 3826 7278 8 1552 1376 11113 15132 2113 1209 24041 1970 8 2337 17 3459 16 8878 17447 7 1895 11113 15132 2113 3689 9 23310 11 5548 525 4603 7 1522 16 10421 11121 8604 11 16924 336 8324 8 954 7 24 2114 1522 3395 5763 56 7 10910 84 1843 23 6538 8324 65 1970 56 4437 110 13 35 2133 463 3750 7 1209 24041 1970 11 4787 26 22135 8 3888 13201 13911 6504 16 2265 1306 238 9 18 7 521 5746 2171 2780 7 11231 11016 5723 10761 23 1581 4540 204 1160 5\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: dokujo-tsushin (id = 0)\r\n",
      "INFO:tensorflow:*** Example ***\r\n",
      "INFO:tensorflow:guid: dev-5\r\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 男に 捨てられ る 女 の特徴 / 100 年の 恋 も 冷め る 女の 態度 など − 【 お気に入り 登録 記事 】 週間 ランキング p e a ch y アプリ を利用し ている 皆 さま 、 アプリ の 「 お気に入り 」 機能 は 使って いますか ? 「 お気に入り 」 と は 、「 あと で また 読み たい !」 と思った 記事 を 登録 すると 、 読み たい ときに いつでも その 記事 を呼び 出せ ちゃう 便利な 機能 です 。 つまり 、「 お気に入り 」 の数 が多い ほど 、 読者 の 関心 を ひ いた 記事 ということ 。 それで は 、 先週 ( 2012 年 8 月 2 日 〜 8 月 8 日 ) 最も 多く 「 お気に入り 」 登録 された 記事 to p 5 を ご 紹介 します ! 第 1 位 : こんな 女 は 捨てられ る ! 男性が 疎 んじ る 女性 と は この世 に 無償 の 愛 など めったに 存在しない 。 まして や 男女 の 愛 など 、 有 償 の 愛 の 最 たる ものである 。 時代 や カップル によって 与え 合う もの 、 求め あう ものは 変わって くる が 、 往 々 にして オン ナ が オ ト コ に求める の は 安心 、 安定 である 。 経済的 安定 であった り 、 愛情 と se x の安定 供給 であった り 、 オン ナ が オ ト コ に求める の は これに 尽き る のである 。 第 2 位 : 気をつけ て ! 男性が 嫌 う 女性の 態度 10 選 女子 力を 日 頃 から 磨 いている みなさん 、 男性の 視線 を気にし ています か ? 多くの 方は 気に している と思います が 、 実際の ところ 、 男性は 女性の どんな 態度 を 嫌 が るのか ご 存 知 でしょうか 。 結構 細かい と ことを 気に している 男性は 多い ものです 。 筆者 は 男性 の立場 として 、 こんなこと された ら 100 年の 恋 も 冷め てしまう かも 、 という 女性の 態度 をお 伝え します の で 、 参考に してください 。 第 3 位 : 1 か 月 − 10 k g ! 確実に 痩 せる ダイエット プログラム が 明らかに 8 月 1 日 発売 の 雑誌 「 po p te en 」 9 月号 は 、「 夏休み ガ チ ヤ セ ダイエット プログラム 31 da y s 」 を 特集 。 しっかり 守 れば 1 ヶ 月 で 10 キロ 痩 せ を 叶 える 夢 の ダイエット プログラム 表 が 公開された 。 第 4 位 : ム ダ 毛 処理 3 つの 注意 ポイント 夏は 薄 着 になる し 、 毛 の処理 に 気を 抜け ない 季節 。 特に 「 水 着 を 着 る !」 なんて ことになる と 、 もう 前の 日は 大変だった り し ませんか ? ▁そして 、 ちゃんと した つもりで も 意外 と 見 落とし があった りして ... 。 そこで 今回は 、 みなさん が 見 落とし がちな ム ダ 毛 処理 の 注意 ポイント 3 つ を ご 紹介 します ! ▁ 意外な ト コロ に 、 毛 が ... 。 第 5 位 : 混ぜて 焼く だけ ! いち ご の クラ フ ティ フランス ・ リ ムー ザン 地方 発祥 の 家庭 的な おやつ 、 [SEP]\r\n",
      "INFO:tensorflow:input_ids: 4 10 11410 21656 47 663 8263 318 221 288 3617 23 24540 47 14630 4010 30 0 660 24549 1428 3051 43 2341 12962 3178 1519 2113 23014 4110 24318 15677 86 4186 3003 7 24318 9 19 24549 13 1520 11 6804 24673 734 19 24549 13 20 11 59 1605 18 212 2686 187 2210 1643 3051 16 1428 753 7 2686 187 4198 12832 96 3051 6219 12828 22343 24611 1520 161 8 6203 59 24549 13 10293 905 414 7 3782 9 2723 16 821 160 3051 2987 8 5831 11 7 17766 15 6238 36 61 37 25 26 0 61 37 61 26 14 1872 2191 19 24549 13 1428 94 3051 7366 3178 38 16 463 2828 837 1202 117 24 431 1022 1126 663 11 21656 47 1202 3974 26294 13623 47 261 20 11 24676 17 8628 9 618 30 25105 29768 8 12658 22 1880 9 618 30 7 671 12216 9 618 9 2499 5978 12454 8 870 22 13462 694 12923 2095 513 7 8046 8990 5046 7385 1590 12 7 12957 680 1750 4595 384 12 519 257 362 18112 9 11 3750 7 2894 155 8 14614 2894 882 91 7 14954 20 17782 17727 13162 3029 882 91 7 4595 384 12 519 257 362 18112 9 11 7866 15071 47 8324 8 117 25 431 1022 15191 66 1202 3974 5113 260 2400 4010 45 1037 455 3019 26 3001 27 8527 4900 7056 7 5750 10769 29331 1722 68 734 841 9085 6855 73 1981 12 7 7903 578 7 2612 2400 1321 4010 16 5113 12 10518 463 9909 807 7418 8 12284 11181 20 398 6855 73 2612 1855 8832 8 19151 11 568 5272 58 7 14911 94 74 221 288 3617 23 24540 2689 5042 7 35 2400 4010 7181 6075 837 9 18 7 18934 13286 8 117 28 431 1022 24 68 37 0 45 4908 4465 1202 7238 0 2851 24441 4643 12 4223 61 37 24 26 2637 9 3274 19 28252 3178 21258 9255 13 64 21094 11 59 4099 953 617 1015 1008 24441 4643 453 25595 4110 1718 13 16 6867 8 3332 1232 512 24 0 37 18 45 302 0 788 16 30907 2641 796 9 24441 4643 980 12 12378 8 117 33 431 1022 633 720 2080 1127 28 2813 2304 1407 17368 2728 755 163 31 7 2080 10987 17 9470 4004 148 4184 8 1311 19 146 755 16 755 47 2210 2140 2352 20 7 898 1270 1765 24087 91 31 9256 734 9244 7 9664 29 13583 23 19115 20 198 9533 222 6854 2788 8 3062 1684 7 7056 12 198 9533 13683 633 720 2080 1127 9 2304 1407 28 274 16 463 2828 837 1202 10 22283 257 9682 17 7 2080 12 2788 8 117 38 431 1022 25064 19425 390 1202 3771 463 9 4705 670 1395 2003 21 330 12095 16782 577 29463 9 1123 254 28246 7 5\r\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\r\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\r\n",
      "INFO:tensorflow:label: peachy (id = 5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Num examples = 1473 (1473 actual, 0 padding)\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (9, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (9,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-02-03:48:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-04-02 12:48:08.487933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2019-04-02 12:48:08.487992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-02 12:48:08.488012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2019-04-02 12:48:08.488027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2019-04-02 12:48:08.488246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7544 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from ../model/livedoor_asahi_output/model.ckpt-11052\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-02-03:48:54\n",
      "INFO:tensorflow:Saving dict for global step 11052: eval_accuracy = 0.10454854, eval_loss = 2.2629395, global_step = 11052, loss = 2.2622628\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11052: ../model/livedoor_asahi_output/model.ckpt-11052\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  eval_accuracy = 0.10454854\n",
      "INFO:tensorflow:  eval_loss = 2.2629395\n",
      "INFO:tensorflow:  global_step = 11052\n",
      "INFO:tensorflow:  loss = 2.2622628\n",
      "CPU times: user 36.4 s, sys: 7.56 s, total: 44 s\n",
      "Wall time: 1h 28min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# It will take many hours on CPU environment.\n",
    "\n",
    "!python3 ../src/run_classifier.py \\\n",
    "  --task_name=livedoor \\\n",
    "  --do_train=true \\\n",
    "  --do_eval=true \\\n",
    "  --data_dir=../data/livedoor \\\n",
    "  --model_file=../model/asahi.model \\\n",
    "  --vocab_file=../model/asahi.vocab \\\n",
    "  --init_checkpoint={PRETRAINED_MODEL_PATH} \\\n",
    "  --max_seq_length=512 \\\n",
    "  --train_batch_size=4 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --num_train_epochs=10 \\\n",
    "  --output_dir={FINETUNE_OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the finetuned model\n",
    "\n",
    "Let's predict test data using the finetuned model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import tokenization_sentencepiece as tokenization\n",
    "from run_classifier import LivedoorProcessor\n",
    "from run_classifier import model_fn_builder\n",
    "from run_classifier import file_based_input_fn_builder\n",
    "from run_classifier import file_based_convert_examples_to_features\n",
    "from utils import str_to_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../bert\")\n",
    "\n",
    "import modeling\n",
    "import optimization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "bert_config_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.json')\n",
    "bert_config_file.write(json.dumps({k:str_to_value(v) for k,v in config['BERT-CONFIG'].items()}))\n",
    "bert_config_file.seek(0)\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ckpts = glob.glob(\"{}/model.ckpt*data*\".format(FINETUNE_OUTPUT_DIR))\n",
    "latest_ckpt = sorted(output_ckpts)[-1]\n",
    "FINETUNED_MODEL_PATH = latest_ckpt.split('.data-00000-of-00001')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    '''Parameters.'''\n",
    "    def __init__(self):\n",
    "        self.model_file = \"../model/asahi.model\"\n",
    "        self.vocab_file = \"../model/asahi.vocab\"\n",
    "        self.do_lower_case = True\n",
    "        self.use_tpu = False\n",
    "        self.output_dir = \"/dummy\"\n",
    "        self.data_dir = \"../data/livedoor\"\n",
    "        self.max_seq_length = 512\n",
    "        self.init_checkpoint = FINETUNED_MODEL_PATH\n",
    "        self.predict_batch_size = 4\n",
    "        \n",
    "        # The following parameters are not used in predictions.\n",
    "        # Just use to create RunConfig.\n",
    "        self.master = None\n",
    "        self.save_checkpoints_steps = 1\n",
    "        self.iterations_per_loop = 1\n",
    "        self.num_tpu_cores = 1\n",
    "        self.learning_rate = 0\n",
    "        self.num_warmup_steps = 0\n",
    "        self.num_train_steps = 0\n",
    "        self.train_batch_size = 0\n",
    "        self.eval_batch_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LivedoorProcessor()\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a trained SentencePiece model.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "    model_file=FLAGS.model_file, vocab_file=FLAGS.vocab_file,\n",
    "    do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=FLAGS.master,\n",
    "    model_dir=FLAGS.output_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "        num_shards=FLAGS.num_tpu_cores,\n",
    "        per_host_input_for_training=is_per_host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f25c0bf8158>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/dummy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f25ccd87320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "WARNING:tensorflow:Setting TPUConfig.num_shards==1 is an unsupported behavior. Please fix as soon as possible (leaving num_shards as None.)\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=FLAGS.init_checkpoint,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    num_train_steps=FLAGS.num_train_steps,\n",
    "    num_warmup_steps=FLAGS.num_warmup_steps,\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    use_one_hot_embeddings=FLAGS.use_tpu)\n",
    "\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=FLAGS.train_batch_size,\n",
    "    eval_batch_size=FLAGS.eval_batch_size,\n",
    "    predict_batch_size=FLAGS.predict_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1473\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-1\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 新記録 で ロンドン に乗り 込む “ バタフライ の 女王 ” 加藤 ゆか 3 日に 行われた 競泳 の 日本選手権 で 、 女子 100 メートル バタフライ の 加藤 ゆか ( 25 歳 ) が 2 大会連続 の 五輪 出場を決めた 。 57 秒 77 と 、 自身が 持つ 日本 新 記録を更新 して の 五輪 切符 ゲ ット だ 。 前回 大会の 北京五輪 選考 では ガ チ ガ チ に 緊張 していたという 加藤 は 、 幾 多 の経験 を得て 、 強い 精神 力を 培った 。 記録 更新 で の 五輪出場 権 獲得 に 、 爽 やかな 笑顔で 喜び を 爆発 させた 。 百 花 繚 乱 の日本 女子 競泳 界 の中でも 、 加藤 は 美 女 スイ マー の 筆頭 に 数え られる 。 目 鼻 立ち の 整った 顔に 、 白く 透 き 通 るような 肌 、 そして 鍛え あげられ た アスリート の 肉体 に 、 ネット 上で の人気 も 上 々 だ 。 前回の 北京五輪 では 予選 敗退 で 悔し 涙 を 呑 んだ 加藤 。 4 年間の 濃 密 な 時間 を経て 、 速く 、 より 美しく なった 「 バタフライ の 女王 」 が 、 ロンドン の プール を 沸 かす 。 ・ 加藤 ゆか ▁ フォト [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 26759 18 4805 4989 1137 1400 24128 9 15256 1388 1823 18244 28 191 5169 25737 9 27637 18 7 455 221 227 24128 9 1823 18244 15 180 152 14 12 25 27800 9 1669 25962 8 1778 376 1619 20 7 9162 6317 103 104 31163 69 9 1669 12528 2829 1453 40 8 1748 6911 18128 4566 52 953 617 953 617 17 3790 6111 1823 11 7 9135 743 8940 8569 7 1248 2792 3019 27571 8 1150 5278 18 9 30223 1010 5200 17 7 27859 8688 7235 3183 16 3495 1254 8 908 284 0 3211 8294 455 25737 2122 11597 7 1823 11 183 663 22043 2660 9 26960 17 11708 604 8 334 5449 1297 9 24994 16561 7 24516 9400 162 379 6793 4942 7 1020 9389 27532 42 31167 9 20697 17 7 1396 2709 9300 23 115 680 40 8 7583 18128 52 3634 13273 18 16199 2872 16 31549 492 1823 8 33 4053 5258 2836 70 226 2691 7 20098 7 202 15682 2496 19 24128 9 15256 13 12 7 4805 9 3836 16 13511 4748 8 21 1823 18244 10 11403 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: sports-watch (id = 7)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-2\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 家電 チャンネル の記事 も 配信 ! 向かう ところ 敵 なし の スマホ アプリ 「 it ニュース ▁ b y ▁ li ve do or ▁ ニュース 」 ▁【 話題 】 n h n ▁ j a p an は 、 同社が 提供する 「 li ve do or ニュース 」 で 配信 している 記事 の中から 、 it 記事 に 特 化した ニュース を まとめて 閲覧 することができる スマートフォン アプリ 「 it ニュース ▁ b y ▁ li ve do or ▁ ニュース 」( i o s ・ and ro i d 対応 / 無料 ) を公開し ている 。 好きな ジャンル の 情報を 逃 さない 向かう ところ 敵 なし の it ニュース リーダー だ 。 というのも 、 この アプリ では li ve do or ニュース の 編集部 が 厳 選 した it 記事 が 提供 される が 、 編集部 の手 作業 によって 「 it ビジネス 」「 w e b サービス 」「 マーケティング 」「 モ バイ ル 」「 デジタル 家電 」 などの 12 の カ テ ゴ リ に 振り 分け られる の で 、 数 ある 情報 の中から 興味 を持った 分野の ニュース のみ を す ば やく チェック できる 。 it ト レン ド を見 落とし たくない 人は 今 すぐ ダウンロード しよう 。 ■ 快適 操作 で 情報 共有 が 簡単 、 雑誌 感覚 で ス ラス ラ 読める 面白かった ニュース は t w it ter や f ac e bo o k など ソー シャル 系 ツ ール で の情報 共有 も可能 。 操作 方法は アイ コン を タッチ する だけで 行 える の で 簡単 だ 。 また 、 記事 ページ を 左右 に フ リック して 次 の記事 を読む ことができる の で 、 雑誌 感覚 で ス ラス ラ 読める 。 記事 ページ 上の フォン ト サイズ 用 ボタン を タッチ することで 文字 サイズ 変更 も可能 だ 。 ■ ランキング 表示 で ト レン ド が 一 目 瞭 然 it ニュース の中でも 人気 記事 を ピック アップ して 紹介している ランキング ページ を チェック すれば 、 忙しい 毎日 でも ト レン ド が 一 目 瞭 然 。 閲覧 履 歴 や ブック マーク の機能 が 充実 しているので 、 気 になった 記事 を いつでも 読み 返す ことができ て 便利 だ 。 it ニュース ▁ b y ▁ li ve do or ▁ ニュース ▁- ▁ it un es ▁ a p p ▁ s to re it ニュース ▁ b y ▁ li ve do or ▁ ニュース ▁- ▁ go o g le ▁ p la y ( 牧 田 ▁ 亜紀 子 ) [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 9623 18437 8804 23 13172 1202 25686 578 3602 1744 9 24936 24318 19 14283 3408 10 4234 4110 10 23484 22612 24926 8318 10 3408 13 44 3055 43 6113 7384 6113 10 11885 2113 3178 8481 11 7 11148 14738 19 23484 22612 24926 8318 3408 13 18 13172 73 3051 3167 7 14283 3051 17 2608 6389 3408 16 12209 15102 20409 22931 24318 19 14283 3408 10 4234 4110 10 23484 22612 24926 8318 10 3408 112 1866 2623 1718 21 27619 11856 1866 4687 972 318 601 14 24538 86 8 3690 17867 9 3382 9738 3945 25686 578 3602 1744 9 14283 3408 5592 40 8 23615 7 87 24318 52 23484 22612 24926 8318 3408 9 7123 12 3639 1037 29 14283 3051 12 923 165 12 7 7123 6137 690 694 19 14283 3190 208 6910 1519 4234 681 208 24683 208 1159 4690 375 208 5491 9623 13 101 102 9 435 1063 1092 330 17 2148 3345 604 9 18 7 247 225 416 3167 5676 4428 13292 3408 1902 16 199 593 12160 3372 238 8 14283 257 2538 532 1183 9533 5231 400 348 2179 28001 3773 8 5054 17101 4762 18 416 7923 12 11876 7 3274 3084 18 157 14397 360 25061 31249 3408 11 3241 6910 14283 27368 22 5957 20217 1519 29141 2623 4908 30 6640 14057 956 624 2325 18 5558 7923 14542 8 4762 15109 2678 1478 16 11239 32 940 359 2641 9 18 11876 40 8 212 7 3051 2296 16 6875 17 670 12916 69 461 8804 10938 3525 9 18 7 3274 3084 18 157 14397 360 25061 8 3051 2296 2389 21352 257 7169 419 13525 16 11239 3732 2654 7169 2494 14542 40 8 5054 12962 2869 18 257 2538 532 12 53 334 31742 7267 14283 3408 11597 1238 3051 16 26460 2597 69 21468 12962 2296 16 3372 833 7 11964 1314 105 257 2538 532 12 53 334 31742 7267 8 15102 13911 6504 22 10929 3689 13947 12 4592 19345 7 389 173 3051 16 12832 2686 6234 11886 66 10210 40 8 14283 3408 10 4234 4110 10 23484 22612 24926 8318 10 3408 676 10 14283 22398 17018 10 2113 3178 3178 10 1718 7366 10382 14283 3408 10 4234 4110 10 23484 22612 24926 8318 10 3408 676 10 20274 2623 4465 15058 10 3178 25808 4110 15 3227 123 10 25245 81 14 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: kaden-channel (id = 2)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-3\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 彼 に あげ たい 韓国 メン ズ コス メ 、 韓 流 俳優 のような 美 肌 男 へ ! 年末 の大 イベント 、 クリスマス まで あと 1 カ月 。 恋人 への プレゼント 選び は 毎回 迷 ってしまう ものです が 、 今年も すでに 何 に しよう か 悩み 始めている 人も多い のではないでしょうか 。 そんな 時は 、 韓国の メン ズ コス メ を チェック して みて は ? 韓国の コス メ ブランド は 、 どこ も メン ズ ライン も 豊富 に 展開 し 、 面倒 くさ が り な 男性 向けに 多 機能 なもの や 、 し わ 改善 や ハリ を与える もの まで 幅広く そろって います 。 最近 人気の 韓 流 スター や k - po p アイドル は 、 みんな 肌 が つ や つ や 。 韓 流 スター のような 美 肌 男 になれる かもしれない 、 韓国の メン ズ コス メ を 3 点 ご 紹介 します ! ■ イ ニ ス フリー ( in ni s f re e ) : ワン ステップ モ イス チャー ▁ フォー マン 1 15 ml / 1 個 ▁1,3 50 円 自然 派 化粧品 の イ ニ ス フリー は 、 メン ズ コス メ の ライン も 豊富 。 韓国の 公式 サイト には 、 男性 商品 用の 専門 コーナー もあり 、 ロ ーション から パック まで 女性 顔 負け の 商品 が ライン ナ ップ しています 。 その中で も 人気 な の が 、 ワン ステップ モ イス チャー ▁ フォー マン 。 ス キン と ロ ーション が ひとつ になった もので 、 ひげ 剃 り による 刺激 や 、 飲酒 、 喫煙 などで 肌 が 荒れ やすくなった 男性の 肌 に 、 ワン ステップ で 水分 を 補給 し 保 湿 します 。 ハーブ の 成分 が 肌 の 血液 循環 を促し 、 男性の 厚い 肌 にも 奥 まで 水分 を届け 、 滑 ら かな 肌 に 仕上げ ます 。 ■ ザ フェイ ス ショップ ( th e ▁ f ac e ▁ s ho p ) : ハーブ & リ リーフ ▁ フ ラッシュ オ ム ▁ シー バ ム フリー ト ナー ( 化粧 水 ) 140 ml / 1 個 ▁1 , 750 円 男性の 肌 は 、 女性 よりも 皮 脂 の 分 泌 量 が多く 、 肌 が 油 っぽ くなる のが特徴 。 ハーブ & リ リーフ ▁ フ ラッシュ オ ム ▁ シー バ ム フリー ト ナー は 、 そんな 肌 を 効果的 に コントロール してくれる オイル フリー の 化粧 水 です 。 ハーブ が 肌 に 爽 快 感 を与え 、 初め は フレッシュ な シ トラ ス 系 の香り 、 そして 、 さわやか で 魅力的な ム スク の香り が 持続 します 。 ■ ス キン フード ( s k in f o o d ) : ミルク ・ グリーン ティー マスク シート ▁ フォー メン 5 枚 入り ▁1,0 00 円 男性の 肌 も 、 時には スペシャル ケア を取り入れ て みて は ? ▁ ミルク ・ グリーン ティー マスク シート ▁ フォー メン は 、 優れた 抗 酸化 効果 を発揮 する 緑 茶 抽出 物 と 、 高い 保 湿 [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 4320 17 5711 187 855 6132 361 23097 773 7 5740 888 6872 1041 183 4942 305 83 1202 6675 2408 963 7 4554 93 1605 24 890 8 14433 97 4073 8400 11 9342 7136 11252 8832 12 7 5554 883 549 17 3773 68 4279 7788 13960 18201 8 830 3708 7 5219 6132 361 23097 773 16 3372 69 7296 11 734 5219 23097 773 2661 11 7 5977 23 6132 361 3125 23 12084 17 2510 31 7 16591 17081 12 91 70 568 7387 743 1520 10821 22 7 31 576 1393 22 16564 7207 513 93 12518 13146 1473 8 2216 8992 5740 888 2747 22 4908 141 28252 3178 18285 11 7 1730 4942 12 274 22 274 22 8 5740 888 2747 1041 183 4942 305 12836 1974 7 5219 6132 361 23097 773 16 28 145 463 2828 837 1202 5054 404 812 157 3679 15 4116 25422 1718 5957 10382 1519 14 1022 3386 15478 1159 9057 6393 10 6694 1064 24 121 30219 318 24 1215 9073 181 76 771 919 12744 9 404 812 157 3679 11 7 6132 361 23097 773 9 3125 23 12084 8 5219 5160 3541 56 7 568 1165 1766 1627 2397 1282 7 411 8543 27 9361 93 261 1018 2640 9 1165 12 3125 384 7256 1797 8 10912 23 1238 70 9 12 7 3386 15478 1159 9057 6393 10 6694 1064 8 157 5834 20 411 8543 12 5653 173 2063 7 25227 0 91 140 5393 22 7 15384 7 10932 240 4942 12 10403 30602 5750 4942 17 7 3386 15478 18 15897 16 11932 31 749 11644 837 8 18678 9 9428 12 4942 9 7319 12118 21794 7 5750 9335 4942 116 1513 93 15897 13764 7 5690 74 1058 4942 17 11853 268 8 5054 1332 30183 157 7276 15 18997 1519 10 5957 20217 1519 10 1718 14802 3178 14 1022 18678 2771 330 19098 10 670 10457 519 633 10 2018 592 633 3679 257 2992 15 12786 146 14 5644 30219 318 24 1215 78 150 14757 76 5750 4942 11 7 261 1784 3968 14927 9 77 28943 1094 1745 7 4942 12 1925 9545 4668 17864 8 18678 2771 330 19098 10 670 10457 519 633 10 2018 592 633 3679 257 2992 11 7 830 4942 16 17954 17 15169 5032 18475 3679 9 12786 146 161 8 18678 12 4942 17 27859 3683 638 4112 7 3172 11 29825 70 516 4152 157 956 14778 7 1020 7 21841 18 27089 633 8316 14778 12 18168 837 8 5054 157 5834 16666 15 1718 4908 4116 5957 2623 2623 4687 14 1022 18409 21 4035 5112 10541 5746 10 6694 6132 38 993 903 7870 1051 76 5750 4942 23 7 3881 20391 4751 14867 66 7296 11 734 10 18409 21 4035 5112 10541 5746 10 6694 6132 11 7 10622 9565 13349 1789 10344 32 1916 1373 17482 317 20 7 1516 749 11644 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: peachy (id = 5)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-4\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 快適 な スマホ ライフ のための 必 須 アプリ 「 マ トリック ス ▁ レ ボ リュ ーション ズ 」( c ) w ar n er ▁ b ro s . ▁ en ter ta in m ent ▁ in c . 「 チャー リーズ ・ エン ジェ ル 」( c ) 2003 ▁ co lu m b i a ▁ p ic t u re s ▁ in d u st ri es , ▁ in c . ▁ all ▁ ri g h t ▁ re s er ve d 「 ダ ・ ヴィ ン チ ・ コード / 字幕版 」( c ) 2006 ▁ co lu m b i a ▁ p ic t u re s ▁ in d u st ri es , ▁ in c . ▁ all ▁ ri g h t s ▁ re s er ve d . 「 ハム ナ プ トラ ▁ 失われた 砂漠 の 都 」( c ) 1999 ▁ un i ver s al ▁ st u di o s . 「 フラ ガール 」( c ) 2006 ▁ b la c k ▁ di am on d s [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 17101 70 24936 6616 1455 27369 3510 24318 19 403 21237 157 10 521 1144 16734 8543 361 112 3453 14 6910 12214 6113 9740 10 4234 11856 1718 189 10 9255 27368 17664 4116 3583 26661 10 4116 3453 189 19 6393 22065 21 3832 3604 375 112 3453 14 12205 10 11471 29909 3583 4234 1866 2113 10 3178 17496 3241 2742 10382 1718 10 4116 4687 2742 15653 15466 17018 150 10 4116 3453 189 10 31543 10 15466 4465 7384 3241 10 10382 1718 9740 22612 4687 19 720 21 7019 798 617 21 13671 318 29101 112 3453 14 9457 10 11471 29909 3583 4234 1866 2113 10 3178 17496 3241 2742 10382 1718 10 4116 4687 2742 15653 15466 17018 150 10 4116 3453 189 10 31543 10 15466 4465 7384 3241 1718 10 10382 1718 9740 22612 4687 189 19 12808 384 1241 4152 10 23059 18046 9 630 112 3453 14 19879 10 22398 1866 31032 1718 16882 10 15653 2742 30312 2623 1718 189 19 9649 15491 112 3453 14 9457 10 4234 25808 3453 4908 10 30312 23999 10632 4687 1718 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: livedoor-homme (id = 3)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test-5\n",
      "INFO:tensorflow:tokens: [CLS] ▁ 独 女 と 上司 の 気になる 関係 人事異動 の多い 春 は 、 職場の 人間関係 の悩み も 増える 時期 。 『 an ・ an 』( 6 月 1 日 号 ) は 、「 みんな 悩んでいる ! 職場の 人間関係 」 特集 だった し 、 日 経 w o m an の 6 月号 も 、 職場の コミュニケーション に関する 記事 が多かった 。 同僚 や 先輩 、 後輩 、 さまざまな 人間関係 がある 中で 、 中堅 社員 として 責任 のある 仕事 が増える 独 女 世代 が 苦労 するのは 、 上司 との関係 かもしれない 。 理解 のある 上司 ならば 、 毎日 が 楽しく 、 仕事 も 伸び やかに できる だろう 。 しかし 、 現実 は 上手 く いかない こと の方が 多い 。 独 女たち は 、 上司 に どんな 不満 や 悩み がある のだろうか ? 「 製品 についての 知識 が 無い 上司 に 困って います 」 と話し てくれた の は ナ オ コ さん ( 27 歳 ・ 営業 ) 。「 他社 から 引き 抜かれ てきた と聞いて いました が 、 ウチ の 会社の 製品 について ほ とん と 知識 が 無い んです 。 商談 に 同行 したとき も 、 上司 が 話す たび ヒ ヤ ヒ ヤ しました 。 なのに プライド ばかり 高く て ... 」 。 さらに 、 ナ オ コ さんの 上司 には 「 猫 が 行方不明になった 」 、「 娘が 学校 に行か なくて 困っている 」 など 、 奥 様 からの 電話 が多い 。「 家庭 内の ことは わからない けれど 、 仕事 どころ ではない のか も 」 と 同情 する 声もある ようだ 。 4 月の 人事異動 で 、 上司 が変わった エ ミ さん ( 31 歳 ・ 営業 事務 ) も 苦労 している 。「 前の 上司 は 大 雑 把 な タイプ で したが 、 新しい 上司 は 、 細かい ところまで 指示 する タイプ で 、 棚 の 書類 や 書籍 の 並べ 方に まで こ だ わる んです 。 今のところ 、 どんな 仕事 も ひとつ ひとつ 報告 して 、 許可 を もらわ ないといけない の で 、 すごく 疲れ ますよ 。 私たち 、 信用 されていない んじゃないか って 、 同僚 と 愚 痴 っています 」 と話し てくれた 。 信頼関係 が 築 け ていない と 、 簡単な ことも 上手 く いかない し ストレス も 溜 まる 。 ちなみに 、 周囲の 独 女たち に 、 嫌い な ( 苦手な ) 上司 の タイプ をあげて もらう と ... 。 ・ 仕事 ができない 、 仕事 の流れ を 把握 できていない 。 ・ 決断 力 がない 。 優 柔 不 断 。 ・ 自慢 が多く 、 プライド が 無駄 に 高い 。 ・ 責任を 部下 に押し 付ける 。 ・ 細かい 仕事 まで 干渉 する 。 口 うるさい 。 ・ 話が 長く 要 点が わからない 。 ・ 気分 屋 。 キレ やすい 。 すぐ 怒鳴 る ・ セクハラ す れ す れ 、 など 。 他に も 「 国立 大卒 が 自慢 で 、 部下 に対して 上から 目線 で 話す 上司 が 嫌 」 ▁( ミサ キ さん ・ 31 歳 ) 。「 自分の 発注 ミス を ごま かす ために 、 短 納 期 で 発注 したり 、 書類 の 催 促 を 大 げ さに してみた り 、 上司 の 横 柄 な [SEP]\n",
      "INFO:tensorflow:input_ids: 4 10 2935 663 20 6375 9 9593 444 22221 8267 473 11 7 18122 14019 17171 23 5037 1752 8 207 8481 21 8481 5782 41 37 24 26 448 14 11 59 1730 25517 1202 18122 14019 13 6867 67 31 7 26 2386 6910 2623 3583 8481 9 41 21094 23 7 18122 7041 927 3051 4180 8 4585 22 4286 7 8753 7 3542 14019 110 1523 7 8157 1255 58 1339 620 639 5813 2935 663 2207 12 4338 1764 7 6375 4982 1974 8 1469 620 6375 6813 7 1314 12 6319 7 639 23 4061 12704 238 562 8 236 7 2753 11 8472 168 9827 147 3390 1855 8 2935 26629 11 7 6375 17 1321 3008 22 4279 110 3587 734 19 1811 5867 3242 12 16736 6375 17 27671 1473 13 4079 2957 9 11 384 519 362 60 15 292 152 21 1043 14 65 14356 27 1275 23765 447 16201 5497 12 7 22751 9 2523 1811 109 1496 12521 20 3242 12 16736 1437 8 25984 17 4546 14270 23 7 6375 12 2982 11253 1359 1015 1359 1015 1456 8 3605 27506 1288 3628 66 2788 13 8 382 7 384 519 362 547 6375 56 19 4024 12 23495 13 59 14359 322 24066 6270 18326 13 30 7 1513 2504 678 190 905 65 1123 717 687 3567 2649 7 639 7335 862 326 23 13 20 25231 32 16816 1224 8 33 608 22221 18 7 6375 13469 597 553 60 15 453 152 21 1043 1896 14 23 4338 73 65 1270 6375 11 48 3467 31832 70 6267 18 1193 7 510 6375 11 7 11181 23410 3069 32 6267 18 7 5224 9 3613 22 12617 9 9846 8216 93 244 40 12444 1437 8 7302 7 1321 639 23 5653 5653 1171 69 7 3352 16 28762 9066 9 18 7 7643 4403 12763 8 3722 7 3618 4009 11155 204 7 4585 20 19618 31821 8341 13 4079 2957 8 17527 12 3645 1001 1149 20 7 12797 1170 8472 168 9827 31 7290 23 31618 2109 8 22419 7 8915 2935 26629 17 7 9051 70 15 27109 14 6375 9 6267 16212 2944 20 2788 8 21 639 10793 7 639 3523 16 6128 14469 8 21 5295 229 760 8 1755 20448 456 1566 8 21 12323 1745 7 27506 12 11573 17 1516 8 21 7757 13354 14063 10027 8 21 11181 639 93 26717 32 8 310 28945 8 21 12794 3485 2171 7130 3567 8 21 3880 469 8 25122 2082 8 2179 24972 47 21 22312 199 826 199 826 7 30 8 10855 23 19 2145 9756 12 12323 18 7 13354 1223 11564 18612 18 2982 6375 12 5113 13 88 24952 599 60 21 453 152 14 65 490 4981 1921 16 23907 4748 1512 7 4711 4199 723 18 4981 1504 7 3613 9 6163 12712 16 48 1795 14379 23791 91 7 6375 9 780 2960 70 5\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: dokujo-tsushin (id = 0)\n"
     ]
    }
   ],
   "source": [
    "predict_examples = processor.get_test_examples(FLAGS.data_dir)\n",
    "predict_file = tempfile.NamedTemporaryFile(mode='w+t', encoding='utf-8', suffix='.tf_record')\n",
    "\n",
    "file_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                        FLAGS.max_seq_length, tokenizer,\n",
    "                                        predict_file.name)\n",
    "\n",
    "predict_drop_remainder = True if FLAGS.use_tpu else False\n",
    "\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "    input_file=predict_file.name,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=predict_drop_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find trained model in model_dir: /dummy, running initialization to predict.\n",
      "WARNING:tensorflow:From ../src/run_classifier.py:425: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (9, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (9,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "CPU times: user 21.9 s, sys: 16.3 s, total: 38.2 s\n",
      "Wall time: 50.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# It will take a few hours on CPU environment.\n",
    "\n",
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'probabilities': array([0.08920389, 0.09514713, 0.16614906, 0.08158392, 0.06454945,\n",
       "         0.1859993 , 0.07285181, 0.12818837, 0.11632711], dtype=float32)},\n",
       " {'probabilities': array([0.08920389, 0.09514713, 0.16614906, 0.08158392, 0.06454945,\n",
       "         0.18599929, 0.07285181, 0.12818837, 0.11632711], dtype=float32)}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test data set and add prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/livedoor/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict'] = [ label_list[elem['probabilities'].argmax()] for elem in result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>新記録でロンドンに乗り込む“バタフライの女王”加藤ゆか3日に行われた競泳の日本選手権で、女子...</td>\n",
       "      <td>sports-watch</td>\n",
       "      <td>peachy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>家電チャンネルの記事も配信！向かうところ敵なしのスマホアプリ「ITニュース by lived...</td>\n",
       "      <td>kaden-channel</td>\n",
       "      <td>peachy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>彼にあげたい韓国メンズコスメ、韓流俳優のような美肌男へ！年末の大イベント、クリスマスまであと...</td>\n",
       "      <td>peachy</td>\n",
       "      <td>peachy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>快適なスマホライフのための必須アプリ「マトリックス レボリューションズ」(c)Warner ...</td>\n",
       "      <td>livedoor-homme</td>\n",
       "      <td>peachy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>独女と上司の気になる関係人事異動の多い春は、職場の人間関係の悩みも増える時期。『an・an』...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>peachy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label predict\n",
       "0  新記録でロンドンに乗り込む“バタフライの女王”加藤ゆか3日に行われた競泳の日本選手権で、女子...    sports-watch  peachy\n",
       "1  家電チャンネルの記事も配信！向かうところ敵なしのスマホアプリ「ITニュース by lived...   kaden-channel  peachy\n",
       "2  彼にあげたい韓国メンズコスメ、韓流俳優のような美肌男へ！年末の大イベント、クリスマスまであと...          peachy  peachy\n",
       "3  快適なスマホライフのための必須アプリ「マトリックス レボリューションズ」(c)Warner ...  livedoor-homme  peachy\n",
       "4  独女と上司の気になる関係人事異動の多い春は、職場の人間関係の悩みも増える時期。『an・an』...  dokujo-tsushin  peachy"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11812627291242363"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( test_df['label'] == test_df['predict'] ) / len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A littel more detailed check using `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/82/c0de5839d613b82bddd088599ac0bbfbbbcbd8ca470680658352d2c435bd/scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 9.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /home/hiroki-iida/.pyenv/versions/anaconda3-5.1.0/envs/py36_ems/lib/python3.6/site-packages (from scikit-learn) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /home/hiroki-iida/.pyenv/versions/anaconda3-5.1.0/envs/py36_ems/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 0.20.1\n",
      "    Uninstalling scikit-learn-0.20.1:\n",
      "      Successfully uninstalled scikit-learn-0.20.1\n",
      "Successfully installed scikit-learn-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.00      0.00      0.00       178\n",
      "  it-life-hack       0.00      0.00      0.00       172\n",
      " kaden-channel       0.00      0.00      0.00       176\n",
      "livedoor-homme       0.00      0.00      0.00        95\n",
      "   movie-enter       0.00      0.00      0.00       158\n",
      "        peachy       0.12      1.00      0.21       174\n",
      "          smax       0.00      0.00      0.00       167\n",
      "  sports-watch       0.00      0.00      0.00       190\n",
      "    topic-news       0.00      0.00      0.00       163\n",
      "\n",
      "     micro avg       0.12      0.12      0.12      1473\n",
      "     macro avg       0.01      0.11      0.02      1473\n",
      "  weighted avg       0.01      0.12      0.02      1473\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiroki-iida/.pyenv/versions/anaconda3-5.1.0/envs/py36_ems/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0 178   0   0   0]\n",
      " [  0   0   0   0   0 172   0   0   0]\n",
      " [  0   0   0   0   0 176   0   0   0]\n",
      " [  0   0   0   0   0  95   0   0   0]\n",
      " [  0   0   0   0   0 158   0   0   0]\n",
      " [  0   0   0   0   0 174   0   0   0]\n",
      " [  0   0   0   0   0 167   0   0   0]\n",
      " [  0   0   0   0   0 190   0   0   0]\n",
      " [  0   0   0   0   0 163   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_df['label'], test_df['predict']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/livedoor/train.tsv\", sep='\\t')\n",
    "dev_df = pd.read_csv(\"../../data/livedoor/dev.tsv\", sep='\\t')\n",
    "test_df = pd.read_csv(\"../../data/livedoor/test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "libmecab-dev is already the newest version (0.996-1.2ubuntu1).\n",
      "mecab is already the newest version (0.996-1.2ubuntu1).\n",
      "mecab-ipadic is already the newest version (2.7.0-20070801+main-1).\n",
      "mecab-ipadic-utf8 is already the newest version (2.7.0-20070801+main-1).\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  libaio1 librados2 librbd1 librdmacm1\n",
      "Use 'sudo apt autoremove' to remove them.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -q -y mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mecab-python3==0.7 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.7)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mecab-python3==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_df = pd.concat([train_df, dev_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_xs = train_dev_df['text'].apply(lambda x: m.parse(x))\n",
    "train_dev_ys = train_dev_df['label']\n",
    "\n",
    "test_xs = test_df['text'].apply(lambda x: m.parse(x))\n",
    "test_ys = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=750)\n",
    "train_dev_xs_ = vectorizer.fit_transform(train_dev_xs)\n",
    "test_xs_ = vectorizer.transform(test_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following set up is not exactly identical to that of BERT because inside Classifier it uses `train_test_split` with shuffle.  \n",
    "In addition, parameters are not well tuned, however, we think it's enough to check the power of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 0 ns, total: 2min 56s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# model = GradientBoostingClassifier(n_estimators=200,\n",
    "#                                   validation_fraction=len(train_df)/len(dev_df),\n",
    "#                                   n_iter_no_change=5,\n",
    "#                                   tol=0.01,\n",
    "#                                   random_state=23)\n",
    "\n",
    "### 1/5 of full training data.\n",
    "model = GradientBoostingClassifier(n_estimators=200,\n",
    "                                    validation_fraction=len(dev_df)/len(train_df),\n",
    "                                    n_iter_no_change=5,\n",
    "                                    tol=0.01,\n",
    "                                    random_state=23)\n",
    "\n",
    "model.fit(train_dev_xs_, train_dev_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.89      0.86      0.88       178\n",
      "  it-life-hack       0.91      0.90      0.91       172\n",
      " kaden-channel       0.90      0.94      0.92       176\n",
      "livedoor-homme       0.79      0.74      0.76        95\n",
      "   movie-enter       0.93      0.96      0.95       158\n",
      "        peachy       0.87      0.92      0.89       174\n",
      "          smax       0.99      1.00      1.00       167\n",
      "  sports-watch       0.93      0.98      0.96       190\n",
      "    topic-news       0.96      0.86      0.91       163\n",
      "\n",
      "     micro avg       0.92      0.92      0.92      1473\n",
      "     macro avg       0.91      0.91      0.91      1473\n",
      "  weighted avg       0.92      0.92      0.91      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_ys, model.predict(test_xs_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[153   4   1   4   2  13   0   1   0]\n",
      " [  3 155   6   3   0   1   0   2   2]\n",
      " [  0   5 165   0   2   0   1   1   2]\n",
      " [  3   4   6  70   4   6   0   1   1]\n",
      " [  1   0   1   3 152   1   0   0   0]\n",
      " [  7   1   1   2   3 160   0   0   0]\n",
      " [  0   0   0   0   0   0 167   0   0]\n",
      " [  1   0   0   2   0   0   0 186   1]\n",
      " [  3   1   3   5   0   3   0   8 140]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_ys, model.predict(test_xs_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
